{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center> Project-5: Question Answering","metadata":{}},{"cell_type":"markdown","source":"**Case Description**\n\nIn this notebook we will train a Question Answering model using DeBERTa.\n\n**Task**\n\nUsing the data to build a Question Answering model.\n\n**Data**: It is a [SberQuAD](https://arxiv.org/pdf/1912.09723) (Sberbank Question Answering Dataset)\n\n**ML/DL task**: Question Answering\n\n*Training on GPU*\n\n`Attention!!! We use only part of the dataset in order to save time to training and GPU reources and memory. That's why metric's final result could be low`","metadata":{}},{"cell_type":"markdown","source":"# 0. Install and Import","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install transformers # the huggingface library containing the general-purpose architectures for NLP\n!pip install datasets # the huggingface library containing datasets and evaluation metrics for NLP\n!pip install evaluate\n!pip install -U ipywidgets\n!pip install optuna\n!pip install -U accelerate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:33:23.147338Z","iopub.execute_input":"2024-12-17T07:33:23.147656Z","iopub.status.idle":"2024-12-17T07:34:24.895617Z","shell.execute_reply.started":"2024-12-17T07:33:23.147625Z","shell.execute_reply":"2024-12-17T07:34:24.894680Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\n\nimport evaluate\nimport optuna\n\n# pytorch libraries\nimport torch\n\nimport transformers\nfrom transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer\nfrom datasets import load_dataset, DatasetDict\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:34:24.897523Z","iopub.execute_input":"2024-12-17T07:34:24.897858Z","iopub.status.idle":"2024-12-17T07:34:44.263600Z","shell.execute_reply.started":"2024-12-17T07:34:24.897820Z","shell.execute_reply":"2024-12-17T07:34:44.262613Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Fixing RANDOM_SEED to make experiment repetable\nRANDOM_SEED = 42\n\n# Set random seeds\ndef set_seed(seed):\n    \"\"\"\n    Helper function for reproducible behavior to set the seed in ``random``, ``numpy``, ``torch`` and/or ``tf`` (if\n    installed).\n\n    Args:\n        seed (:obj:`int`): The seed to set.\n    \"\"\"\n    np.random.seed(seed)\n    random.seed(seed)\n#     tf.random.set_seed(seed)\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    \n    \nset_seed(RANDOM_SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:34:44.264892Z","iopub.execute_input":"2024-12-17T07:34:44.265503Z","iopub.status.idle":"2024-12-17T07:34:44.276899Z","shell.execute_reply.started":"2024-12-17T07:34:44.265474Z","shell.execute_reply":"2024-12-17T07:34:44.276056Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Fixing package versions to make experiment repetable\n!pip freeze > requirements.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:34:44.279432Z","iopub.execute_input":"2024-12-17T07:34:44.280315Z","iopub.status.idle":"2024-12-17T07:34:46.901443Z","shell.execute_reply.started":"2024-12-17T07:34:44.280287Z","shell.execute_reply":"2024-12-17T07:34:46.900363Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"model_name = \"timpal0l/mdeberta-v3-base-squad2\" # Improving DeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangled Embedding Sharing\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:34:46.902793Z","iopub.execute_input":"2024-12-17T07:34:46.903141Z","iopub.status.idle":"2024-12-17T07:34:49.012468Z","shell.execute_reply.started":"2024-12-17T07:34:46.903109Z","shell.execute_reply":"2024-12-17T07:34:49.011630Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/453 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ce338dac6ca468aac7c9b069398b9fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/16.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e14df364bb147cf87d769b59effecba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a53e01ac962940dcae625b2b981796ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/173 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2307b41693745eb84b514eb7840754e"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# If we have a GPU available, we'll set our device to GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:34:49.013638Z","iopub.execute_input":"2024-12-17T07:34:49.013991Z","iopub.status.idle":"2024-12-17T07:34:49.079263Z","shell.execute_reply.started":"2024-12-17T07:34:49.013931Z","shell.execute_reply":"2024-12-17T07:34:49.078131Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# 1. Data Loading: dataset exploration","metadata":{}},{"cell_type":"code","source":"# Load the SBERQUAD dataset - https://huggingface.co/datasets/kuznetsoffandrey/sberquad\ndataset = load_dataset(\"sberquad\")\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:34:49.080392Z","iopub.execute_input":"2024-12-17T07:34:49.080745Z","iopub.status.idle":"2024-12-17T07:34:52.683661Z","shell.execute_reply.started":"2024-12-17T07:34:49.080705Z","shell.execute_reply":"2024-12-17T07:34:52.682640Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/5.16k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b05e2d1cce5452b9360bf98da92d805"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/11.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0c8be46d2cd4837a8decd490c26968d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/3.43M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f278f58a2d4d4a8eabe1cffc79877969"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/4.93M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3586fb803a62450ca056f9c1e726434f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/45328 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e24e319a905b4b62a7006b9f2793f4f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/5036 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1d2619079e447cf8de64b5a43f3276f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/23936 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4db98f51e8934d9a8d8ec87ff3eea65b"}},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 45328\n    })\n    validation: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 5036\n    })\n    test: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 23936\n    })\n})"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"There are several important fields here:\n\n* **answers**: the starting location of the answer token and the answer text.\n* **context**: background information from which the model needs to extract the answer.\n* **question**: the question a model should answer.","metadata":{}},{"cell_type":"code","source":"\"\"\"\nLet's look at the number of examples in train set\n\"\"\"\nprint(\"Number of examples in Context: \", len(dataset[\"train\"][\"context\"]))\nprint(\"Number of examples in Question: \", len(dataset[\"train\"][\"question\"]))\nprint(\"Number of examples in Answer: \", len(dataset[\"train\"][\"answers\"]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:34:52.684922Z","iopub.execute_input":"2024-12-17T07:34:52.685242Z","iopub.status.idle":"2024-12-17T07:34:53.342780Z","shell.execute_reply.started":"2024-12-17T07:34:52.685213Z","shell.execute_reply":"2024-12-17T07:34:53.341843Z"}},"outputs":[{"name":"stdout","text":"Number of examples in Context:  45328\nNumber of examples in Question:  45328\nNumber of examples in Answer:  45328\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Examples of train dataset\nprint(\"Context: \", dataset[\"train\"][1][\"context\"])\nprint(\"\\nQuestion: \", dataset[\"train\"][1][\"question\"])\nprint(\"\\nAnswer: \", dataset[\"train\"][1][\"answers\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:34:53.344100Z","iopub.execute_input":"2024-12-17T07:34:53.344521Z","iopub.status.idle":"2024-12-17T07:34:53.351077Z","shell.execute_reply.started":"2024-12-17T07:34:53.344476Z","shell.execute_reply":"2024-12-17T07:34:53.350114Z"}},"outputs":[{"name":"stdout","text":"Context:  В протерозойских отложениях органические остатки встречаются намного чаще, чем в архейских. Они представлены известковыми выделениями сине-зелёных водорослей, ходами червей, остатками кишечнополостных. Кроме известковых водорослей, к числу древнейших растительных остатков относятся скопления графито-углистого вещества, образовавшегося в результате разложения Corycium enigmaticum. В кремнистых сланцах железорудной формации Канады найдены нитевидные водоросли, грибные нити и формы, близкие современным кокколитофоридам. В железистых кварцитах Северной Америки и Сибири обнаружены железистые продукты жизнедеятельности бактерий.\n\nQuestion:  что найдено в кремнистых сланцах железорудной формации Канады?\n\nAnswer:  {'text': ['нитевидные водоросли, грибные нити'], 'answer_start': [438]}\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Number of examples in validation set\nprint(\"Number of examples in Context (validation set): \", len(dataset[\"validation\"][\"context\"]))\nprint(\"Number of examples in Question (validation set): \", len(dataset[\"validation\"][\"question\"]))\nprint(\"Number of examples in Answer (validation set): \", len(dataset[\"validation\"][\"answers\"]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:34:53.353414Z","iopub.execute_input":"2024-12-17T07:34:53.353705Z","iopub.status.idle":"2024-12-17T07:34:53.434440Z","shell.execute_reply.started":"2024-12-17T07:34:53.353678Z","shell.execute_reply":"2024-12-17T07:34:53.433574Z"}},"outputs":[{"name":"stdout","text":"Number of examples in Context (validation set):  5036\nNumber of examples in Question (validation set):  5036\nNumber of examples in Answer (validation set):  5036\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Example of val set\nprint(\"Context (validation set): \", dataset[\"validation\"][1][\"context\"])\nprint(\"\\nQuestion (validation set): \", dataset[\"validation\"][1][\"question\"])\nprint(\"\\nAnswer (validation set): \", dataset[\"validation\"][1][\"answers\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:34:53.435462Z","iopub.execute_input":"2024-12-17T07:34:53.435723Z","iopub.status.idle":"2024-12-17T07:34:53.441994Z","shell.execute_reply.started":"2024-12-17T07:34:53.435698Z","shell.execute_reply":"2024-12-17T07:34:53.440970Z"}},"outputs":[{"name":"stdout","text":"Context (validation set):  Первые упоминания о строении человеческого тела встречаются в Древнем Египте. В XXVII веке до н. э. египетский врач Имхотеп описал некоторые органы и их функции, в частности головной мозг, деятельность сердца, распространение крови по сосудам. В древнекитайской книге Нейцзин (XI—VII вв. до н. э.) упоминаются сердце, печень, лёгкие и другие органы тела человека. В индийской книге Аюрведа ( Знание жизни , IX-III вв. до н. э.) содержится большой объём анатомических данных о мышцах, нервах, типах телосложения и темперамента, головном и спинном мозге.\n\nQuestion (validation set):  Когда египетский врач Имхотеп впервые описал некоторые органы и их функции?\n\nAnswer (validation set):  {'text': ['В XXVII веке до н. э.'], 'answer_start': [78]}\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"\"\"\"\nIf we use the whole dataset we'll lose a lot of time at the training stage - around 4 hours!!!\nIt will be better to use small part of the dataset in order to look how optuna hyperparams optimization works\n\"\"\"\ndataset_part = load_dataset(\"sberquad\", split='train[:5000]+validation[:1250]')\ndataset = dataset_part.train_test_split(train_size=5000)\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:34:53.443213Z","iopub.execute_input":"2024-12-17T07:34:53.443503Z","iopub.status.idle":"2024-12-17T07:34:54.825410Z","shell.execute_reply.started":"2024-12-17T07:34:53.443475Z","shell.execute_reply":"2024-12-17T07:34:54.824408Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 5000\n    })\n    test: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 1250\n    })\n})"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"# 2. Steps before model building: data preparation\n\nWe want to get data at the next format:\r\n\r\n[CLS] question [SEP] context [SEP]","metadata":{}},{"cell_type":"code","source":"\"\"\"\nCheck results\n\"\"\"\ncontext = dataset[\"train\"][1][\"context\"]\nquestion = dataset[\"train\"][1][\"question\"]\n\ninputs = tokenizer(question, context)\ntokenizer.decode(inputs[\"input_ids\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:34:54.826430Z","iopub.execute_input":"2024-12-17T07:34:54.826765Z","iopub.status.idle":"2024-12-17T07:34:54.838973Z","shell.execute_reply.started":"2024-12-17T07:34:54.826734Z","shell.execute_reply":"2024-12-17T07:34:54.838016Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"'[CLS] Когда в состав РСД вошла Международная рабочая партия?[SEP] В марте 2011 года путём объединения Социалистического движения Вперед (российская секция Четвертого интернационала) и организации Социалистическое сопротивление было создано Российское социалистическое движение[22]. В дальнейшем, к нему присоединились другие троцкистские организации. В апреле 2011 года к РСД присоединилось пермское отделение Революционной рабочей партии. В мае 2012 года в состав РСД вошла Международная рабочая партия (российская секция Международной лиги трудящихся — Четвёртого интернационала)[23]. В составе РСД действуют группы сторонников Четвёртого интернационала и Международной лиги трудящихся — Четвёртого интернационала[24][23].[SEP]'"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"print(\"cls_token: \", tokenizer.cls_token)\nprint(\"sep_token: \", tokenizer.sep_token)\nprint(\"eos_token: \", tokenizer.eos_token)\nprint(\"pad_token: \", tokenizer.pad_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:34:54.840010Z","iopub.execute_input":"2024-12-17T07:34:54.840259Z","iopub.status.idle":"2024-12-17T07:34:54.844959Z","shell.execute_reply.started":"2024-12-17T07:34:54.840234Z","shell.execute_reply":"2024-12-17T07:34:54.844002Z"}},"outputs":[{"name":"stdout","text":"cls_token:  [CLS]\nsep_token:  [SEP]\neos_token:  [SEP]\npad_token:  [PAD]\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"So we see that the model checkpoint we're using uses the [CLS] token to denote the start of the question, then a [SEP] token to mark between the question and the context, and then is ended with another [SEP] token. This is in accordance with how SQUAD is defined.","metadata":{}},{"cell_type":"markdown","source":"**Every transformer model**, no matter how powerful, **has a maximum sequence length that it can handle**.\n\nLet's look at the length for the input IDs without any truncation","metadata":{}},{"cell_type":"code","source":"max_len = []\n\nfor i in range(0, len(dataset[\"train\"][\"question\"])):\n    lenght = len(tokenizer(dataset[\"train\"][i][\"question\"], dataset[\"train\"][i][\"context\"])[\"input_ids\"])\n    max_len.append(lenght)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:34:54.911175Z","iopub.execute_input":"2024-12-17T07:34:54.911419Z","iopub.status.idle":"2024-12-17T07:35:01.042458Z","shell.execute_reply.started":"2024-12-17T07:34:54.911396Z","shell.execute_reply":"2024-12-17T07:35:01.041656Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"print(f'Max length without any truncation: {max(max_len)}')\nprint(f'Index of example with max length: {max_len.index(max(max_len))}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:35:01.043959Z","iopub.execute_input":"2024-12-17T07:35:01.044251Z","iopub.status.idle":"2024-12-17T07:35:01.049635Z","shell.execute_reply.started":"2024-12-17T07:35:01.044222Z","shell.execute_reply":"2024-12-17T07:35:01.048629Z"}},"outputs":[{"name":"stdout","text":"Max length without any truncation: 994\nIndex of example with max length: 4391\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"print(f'Minimum length without any truncation: {min(max_len)}')\nprint(f'Index of example with min length: {max_len.index(min(max_len))}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:35:01.050605Z","iopub.execute_input":"2024-12-17T07:35:01.050864Z","iopub.status.idle":"2024-12-17T07:35:01.063765Z","shell.execute_reply.started":"2024-12-17T07:35:01.050839Z","shell.execute_reply":"2024-12-17T07:35:01.062982Z"}},"outputs":[{"name":"stdout","text":"Minimum length without any truncation: 103\nIndex of example with min length: 474\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"max_len[:5]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:35:01.065702Z","iopub.execute_input":"2024-12-17T07:35:01.066133Z","iopub.status.idle":"2024-12-17T07:35:01.077570Z","shell.execute_reply.started":"2024-12-17T07:35:01.066093Z","shell.execute_reply":"2024-12-17T07:35:01.076804Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"[325, 194, 310, 163, 202]"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"\"\"\"\nLet's look at the length for the input IDs with any truncation\n\"\"\"\nmax_len_trunc = []\n\nfor i in range(0, len(dataset[\"train\"][\"question\"])):\n    lenght_trunc = len(tokenizer(dataset[\"train\"][i][\"question\"], dataset[\"train\"][i][\"context\"],\n                                 max_length=384, truncation=\"only_second\")[\"input_ids\"])\n    max_len_trunc.append(lenght_trunc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:35:03.932123Z","iopub.execute_input":"2024-12-17T07:35:03.932853Z","iopub.status.idle":"2024-12-17T07:35:10.053485Z","shell.execute_reply.started":"2024-12-17T07:35:03.932806Z","shell.execute_reply":"2024-12-17T07:35:10.052695Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"print(f'Max length after truncation: {max(max_len_trunc)}')\nprint(f'Index of example with max length: {max_len_trunc.index(max(max_len_trunc))}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:35:10.055167Z","iopub.execute_input":"2024-12-17T07:35:10.055480Z","iopub.status.idle":"2024-12-17T07:35:10.060174Z","shell.execute_reply.started":"2024-12-17T07:35:10.055451Z","shell.execute_reply":"2024-12-17T07:35:10.059234Z"}},"outputs":[{"name":"stdout","text":"Max length after truncation: 384\nIndex of example with max length: 23\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"print(f'Minimum length after truncation: {min(max_len_trunc)}')\nprint(f'Index of example with min length: {max_len_trunc.index(min(max_len_trunc))}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:35:10.061313Z","iopub.execute_input":"2024-12-17T07:35:10.062151Z","iopub.status.idle":"2024-12-17T07:35:10.070628Z","shell.execute_reply.started":"2024-12-17T07:35:10.062110Z","shell.execute_reply":"2024-12-17T07:35:10.069782Z"}},"outputs":[{"name":"stdout","text":"Minimum length after truncation: 103\nIndex of example with min length: 474\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"In fact, unlike RNNs, transformers need a fixed input length to match up to their internals. So even short input will need to be padded.\n\nBut how can we handle training examples where the question + context exceeds the max length of the current architecture? We don't just want to cut off the context, as the answer may be contained in it, and we'll lose valuable training data.\n\nThe solution is, similar to time-series applications, we'll window the data into smaller chunks. We only window the context, and the question is never modified.","metadata":{}},{"cell_type":"markdown","source":"### `There are a few preprocessing steps particular to question answering tasks:`\n\n- Some examples in a dataset may have a very long context that exceeds the maximum input length of the model. To deal with longer sequences, truncate only the context by setting *truncation=\"only_second\"*. Note that **we never want to truncate the question**, only the context, else the only_second truncation picked\n- Map the start and end positions of the answer to the original context by setting *return_offset_mapping=True*\n- Use the *sequence_ids* method to find which part of the offset corresponds to the **question** and which corresponds to the **context**\n\nIn the labeled dataset, **answer_start** gives us the correponding location of the answer within the context string. Note that it's relative to the start of the context string, not the question + context. The answer **text** gives us the actual plaintext answer, from which we can easily calculate the answer_end position as just **answer_start plus the length of the answer**.\n\nThis format is not sufficient to train from — we'll need labels for both start and end positions.","metadata":{}},{"cell_type":"code","source":"MAX_LENGTH = 384 #The maximum length of a feature (question and context)\nSTRIDE = 128 #The authorized overlap between two part of the context when splitting it is needed. 64 - corrected else: PanicException: assertion failed: stride < max_len when using Question-Answering pipeline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:36:42.164914Z","iopub.execute_input":"2024-12-17T07:36:42.165281Z","iopub.status.idle":"2024-12-17T07:36:42.169976Z","shell.execute_reply.started":"2024-12-17T07:36:42.165251Z","shell.execute_reply":"2024-12-17T07:36:42.168826Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"We need to use **different functions to preprocess training and validation dataset** by information from [repository](https://github.com/huggingface/transformers/blob/main/examples/pytorch/question-answering/run_qa.py) (fine-tuning models for the QA task).\n\nBut during training process I want to check two key metrics used by many question answering datasets, including SQuAD: **exact match (EM)** and **F1 score**. That's why I'll use the same function to preprocess all data.\n\r\nNext you will see 2 ocode snippets.","metadata":{}},{"cell_type":"code","source":"\"\"\"\nDifferent fuctions to preprocess training and validation examples\n\npreprocess_validation_examples: If there is no need to generate class labels for tokens.\n\"\"\"\n# # Training set\n# # Function to truncate and map the start and end tokens of the answer to the context\n# def preprocess_training_examples(examples):\n#     questions = [q.strip() for q in examples['question']]\n#     inputs = tokenizer(\n#         questions,\n#         examples['context'],\n#         max_length=MAX_LENGTH,\n#         truncation='only_second',\n#         stride=STRIDE,\n#         # return_overflowing_tokens=True,\n#         return_offsets_mapping=True,\n#         padding='max_length',\n#         )\n\n#     # sample_map = inputs.pop('overflow_to_sample_mapping')\n#     offset_mapping = inputs['offset_mapping']\n#     answers = examples['answers']\n#     start_positions = []\n#     end_positions = []\n\n#     for (i, offset) in enumerate(offset_mapping):\n#         # sample_idx = sample_map[i]\n#         answer = answers[i]\n#         start_char = answer['answer_start'][0]\n#         end_char = answer['answer_start'][0] + len(answer['text'][0])\n#         sequence_ids = inputs.sequence_ids(i)\n\n#     # Find the start and end of the context\n\n#         idx = 0\n#         while sequence_ids[idx] != 1:\n#             idx += 1\n#         context_start = idx\n#         while sequence_ids[idx] == 1:\n#             idx += 1\n#         context_end = idx - 1\n\n#     # If the answer is not fully inside the context, label is (0, 0)\n\n#         if offset[context_start][0] > end_char \\\n#             or offset[context_end][1] < start_char:\n#             start_positions.append(0)\n#             end_positions.append(0)\n#         else:\n\n#       # Otherwise it's the start and end token positions\n\n#             idx = context_start\n#             while idx <= context_end and offset[idx][0] <= start_char:\n#                 idx += 1\n#             start_positions.append(idx - 1)\n\n#             idx = context_end\n#             while idx >= context_start and offset[idx][1] >= end_char:\n#                 idx -= 1\n#             end_positions.append(idx + 1)\n\n#     inputs['start_positions'] = start_positions\n#     inputs['end_positions'] = end_positions\n    \n#     return inputs\n\n\n# # To apply the preprocessing function over the entire dataset\n# # We can speed up the map function by setting batched=True to process multiple elements of the dataset at once\n# train_dataset = dataset_part[\"train\"].map(\n#     preprocess_training_examples,\n#     batched=True,\n#     remove_columns=dataset[\"train\"].column_names\n# )\n\n\n# # Validation/Test set\n# # Function to truncate and map the start and end tokens of the answer to the context\n# def preprocess_validation_examples(examples):\n#     questions = [q.strip() for q in examples['question']]\n#     inputs = tokenizer(\n#         questions,\n#         examples['context'],\n#         max_length=MAX_LENGTH,\n#         truncation='only_second',\n#         stride=STRIDE,\n#         # return_overflowing_tokens=True,\n#         return_offsets_mapping=True,\n#         padding='max_length',\n#         )\n\n#     # sample_map = inputs.pop('overflow_to_sample_mapping')\n#     example_ids = []\n\n#     for i in range(len(inputs['input_ids'])):\n#         # sample_idx = sample_map[i]\n#         example_ids.append(examples['id'][i])\n\n#         sequence_ids = inputs.sequence_ids(i)\n#         offset = inputs['offset_mapping'][i]\n#         inputs['offset_mapping'][i] = [(o if sequence_ids[k]\n#                 == 1 else None) for (k, o) in enumerate(offset)]\n\n\n#     inputs['example_id'] = example_ids\n\n#     return inputs\n\n\n# validation_dataset = dataset_part[\"test\"].map(\n#     preprocess_validation_examples,\n#     batched=True,\n#     remove_columns=dataset_part[\"test\"].column_names\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:37:39.495741Z","iopub.execute_input":"2024-12-17T07:37:39.496129Z","iopub.status.idle":"2024-12-17T07:37:39.504720Z","shell.execute_reply.started":"2024-12-17T07:37:39.496096Z","shell.execute_reply":"2024-12-17T07:37:39.503666Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"'\\nDifferent fuctions to preprocess training and validation examples\\n\\npreprocess_validation_examples: If there is no need to generate class labels for tokens.\\n'"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"\"\"\"\nThe same function for both dataset\n\"\"\"\ndef preprocess_examples(examples):\n    questions = [q.strip() for q in examples['question']]\n    inputs = tokenizer(\n        questions,\n        examples['context'],\n        max_length=MAX_LENGTH,\n        truncation='only_second', # Only truncate/window the context, not question!\n        stride=STRIDE,\n        return_offsets_mapping=True, #To also pass the truncated tokens to the model, we can use this parameter\n        padding='max_length', # Added a padding strategy to make all batches same\n        )\n\n    offset_mapping = inputs['offset_mapping']\n    answers = examples['answers']\n    start_positions = []\n    end_positions = []\n\n    for i, offset in enumerate(offset_mapping):\n        answer = answers[i]\n        start_char = answer['answer_start'][0]\n        end_char = answer['answer_start'][0] + len(answer['text'][0])\n        sequence_ids = inputs.sequence_ids(i)\n\n    # Find the start and end of the context\n\n        idx = 0\n        while sequence_ids[idx] != 1:\n            idx += 1\n        context_start = idx\n        while sequence_ids[idx] == 1:\n            idx += 1\n        context_end = idx - 1\n\n    # If the answer is not fully inside the context, label is (0, 0)\n\n        if offset[context_start][0] > end_char \\\n            or offset[context_end][1] < start_char:\n            start_positions.append(0)\n            end_positions.append(0)\n        else:\n\n      # Otherwise it's the start and end token positions\n\n            idx = context_start\n            while idx <= context_end and offset[idx][0] <= start_char:\n                idx += 1\n            start_positions.append(idx - 1)\n\n            idx = context_end\n            while idx >= context_start and offset[idx][1] >= end_char:\n                idx -= 1\n            end_positions.append(idx + 1)\n\n    inputs['start_positions'] = start_positions\n    inputs['end_positions'] = end_positions\n    \n    return inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:37:40.697918Z","iopub.execute_input":"2024-12-17T07:37:40.698655Z","iopub.status.idle":"2024-12-17T07:37:40.707540Z","shell.execute_reply.started":"2024-12-17T07:37:40.698602Z","shell.execute_reply":"2024-12-17T07:37:40.706536Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# DATASETS_for_optuna - Reduce the dataset to speed up the process of selecting hyperparameters\npart_of_data = 0.1\n\nDATASETS_for_optuna = DatasetDict({\n    'train': dataset[\"train\"].map(\n        preprocess_examples,\n        batched=True).select(\n            np.random.choice(range(len(dataset[\"train\"])), int(len(dataset[\"train\"])*part_of_data), replace=False)\n        ),\n    'validation': dataset[\"test\"].map(\n        preprocess_examples,\n        batched=True).select(\n            np.random.choice(range(len(dataset[\"test\"])), int(len(dataset[\"test\"])*part_of_data), replace=False)\n        )\n})\nDATASETS_for_optuna","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:37:41.667127Z","iopub.execute_input":"2024-12-17T07:37:41.667934Z","iopub.status.idle":"2024-12-17T07:37:50.529678Z","shell.execute_reply.started":"2024-12-17T07:37:41.667898Z","shell.execute_reply":"2024-12-17T07:37:50.528897Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b2ceabb9ccc423eacd12957a46a260b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ce15249421d4ca28ef975fa8776f38b"}},"metadata":{}},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers', 'input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'start_positions', 'end_positions'],\n        num_rows: 500\n    })\n    validation: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers', 'input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'start_positions', 'end_positions'],\n        num_rows: 125\n    })\n})"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"\"\"\"\nTo apply the preprocessing function over the entire dataset - train and validation\nWe can speed up the map function by setting batched=True to process multiple elements of the dataset at once\n\"\"\"\n\nDATASETS = DatasetDict({\n    'train': dataset[\"train\"].map(\n        preprocess_examples,\n        batched=True).select(\n            np.random.choice(range(len(dataset[\"train\"])), int(len(dataset[\"train\"])), replace=False)\n        ),\n    'validation': dataset[\"test\"].map(\n        preprocess_examples,\n        batched=True).select(\n            np.random.choice(range(len(dataset[\"test\"])), int(len(dataset[\"test\"])), replace=False)\n        )\n})\nDATASETS","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:37:50.530879Z","iopub.execute_input":"2024-12-17T07:37:50.531200Z","iopub.status.idle":"2024-12-17T07:37:57.409671Z","shell.execute_reply.started":"2024-12-17T07:37:50.531173Z","shell.execute_reply":"2024-12-17T07:37:57.408781Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60309e54ff794d6e9311fb117486514a"}},"metadata":{}},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers', 'input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'start_positions', 'end_positions'],\n        num_rows: 5000\n    })\n    validation: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers', 'input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'start_positions', 'end_positions'],\n        num_rows: 1250\n    })\n})"},"metadata":{}}],"execution_count":26},{"cell_type":"markdown","source":"# 3. Model training\n\n\nKey steps\n* Define metric computation function\n* Training model with base hyperparameters\n* Getting the best hyperparameters by optuna (automatic hyperparameter optimizations)\n* Training model with the best hyperparameters\n\n`Attention!!! We use only part of the dataset in order to save time to training and GPU resources. That's why metric's final result could be low`.","metadata":{}},{"cell_type":"markdown","source":"## 3.1 Metric computation function","metadata":{}},{"cell_type":"code","source":"# Define metric to compute\nmetric = evaluate.load(\"squad\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:38:00.668646Z","iopub.execute_input":"2024-12-17T07:38:00.669616Z","iopub.status.idle":"2024-12-17T07:38:01.318554Z","shell.execute_reply.started":"2024-12-17T07:38:00.669576Z","shell.execute_reply":"2024-12-17T07:38:01.317579Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.53k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9094ffcc734472ca21d2f70a2f64447"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d37655bb891842a7b89a3ff23d73f004"}},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"def compute_metrics_for_optuna(eval_preds):\n    y_pred = np.argmax(eval_preds[0], -1).T\n\n    f1_score = 0\n    exact_match = 0\n    \n    for data, pred in zip(DATASETS_for_optuna['validation'], y_pred):\n        # Convert answer start and end into characters positions in\n        # original text using the offset mapping list\n        start_char = data['offset_mapping'][pred[0]][0]\n        end_char = data['offset_mapping'][pred[1]][1]\n        \n        # Create predictions and references dictionaries for metric function\n        predictions = [{'prediction_text': data['context'][start_char:end_char],\n                        'id': str(data['id'])}]\n        references = [{'answers': data['answers'],\n                       'id': str(data['id'])}]\n        results = metric.compute(predictions=predictions,\n                                 references=references)\n        \n        # Add metric to running sum variable to calculate average after,\n        # change outputs from 0-100 range to 0-1 range\n        f1_score += results['f1'] / 100\n        exact_match += results['exact_match'] / 100\n        \n    # Calculate the average\n    f1_score /= len(DATASETS_for_optuna['validation'])\n    exact_match /= len(DATASETS_for_optuna['validation'])\n    \n    return {'f1': f1_score, 'exact_match': exact_match}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:38:02.377159Z","iopub.execute_input":"2024-12-17T07:38:02.377933Z","iopub.status.idle":"2024-12-17T07:38:02.384806Z","shell.execute_reply.started":"2024-12-17T07:38:02.377901Z","shell.execute_reply":"2024-12-17T07:38:02.383733Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"def compute_metrics(eval_preds):\n    y_pred = np.argmax(eval_preds[0], -1).T\n\n    f1_score = 0\n    exact_match = 0\n    \n    for data, pred in zip(DATASETS['validation'], y_pred):\n        # Convert answer start and end into characters positions in\n        # original text using the offset mapping list\n        start_char = data['offset_mapping'][pred[0]][0]\n        end_char = data['offset_mapping'][pred[1]][1]\n        \n        # Create predictions and references dictionaries for metric function\n        predictions = [{'prediction_text': data['context'][start_char:end_char],\n                        'id': str(data['id'])}]\n        references = [{'answers': data['answers'],\n                       'id': str(data['id'])}]\n        results = metric.compute(predictions=predictions,\n                                 references=references)\n        \n        # Add metric to running sum variable to calculate average after,\n        # change outputs from 0-100 range to 0-1 range\n        f1_score += results['f1'] / 100\n        exact_match += results['exact_match'] / 100\n        \n    # Calculate the average\n    f1_score /= len(DATASETS['validation'])\n    exact_match /= len(DATASETS['validation'])\n    \n    return {'f1': f1_score, 'exact_match': exact_match}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:38:03.853257Z","iopub.execute_input":"2024-12-17T07:38:03.853594Z","iopub.status.idle":"2024-12-17T07:38:03.861054Z","shell.execute_reply.started":"2024-12-17T07:38:03.853562Z","shell.execute_reply":"2024-12-17T07:38:03.860004Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"## 3.2 Training model with base hyperparams","metadata":{}},{"cell_type":"code","source":"# TRAINING HYPERPARAMS\nBATCH_SIZE = 12\nNUM_EPOCHS = 5\nLR = 3e-5\nWD = 0.01\nGRAD_ACC = 8\nWARMUP = 0.1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T14:28:38.090359Z","iopub.execute_input":"2024-12-16T14:28:38.090727Z","iopub.status.idle":"2024-12-16T14:28:38.095207Z","shell.execute_reply.started":"2024-12-16T14:28:38.090696Z","shell.execute_reply":"2024-12-16T14:28:38.094260Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"training_args_base = TrainingArguments(\"mdeberta-squad-base-params\",\n                                  evaluation_strategy=\"steps\",\n                                  eval_steps=50,\n                                  logging_steps=50,\n                                  save_steps=100,\n                                  optim=\"adamw_torch\",\n                                  learning_rate=LR,\n                                  per_device_train_batch_size=BATCH_SIZE,\n                                  per_device_eval_batch_size=BATCH_SIZE,\n                                  warmup_steps=50,\n                                  lr_scheduler_type='cosine',\n                                  weight_decay=WD,\n                                  warmup_ratio=WARMUP,\n                                  gradient_accumulation_steps=GRAD_ACC,\n                                  num_train_epochs=NUM_EPOCHS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T14:28:39.142094Z","iopub.execute_input":"2024-12-16T14:28:39.142914Z","iopub.status.idle":"2024-12-16T14:28:39.209551Z","shell.execute_reply.started":"2024-12-16T14:28:39.142880Z","shell.execute_reply":"2024-12-16T14:28:39.208714Z"}},"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"model = AutoModelForQuestionAnswering.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T14:28:40.180509Z","iopub.execute_input":"2024-12-16T14:28:40.180790Z","iopub.status.idle":"2024-12-16T14:28:45.422415Z","shell.execute_reply.started":"2024-12-16T14:28:40.180765Z","shell.execute_reply":"2024-12-16T14:28:45.421592Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/879 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d5664aead6d416ca4229e6e0f4a11cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"188fbef4a5024c63b227b88a8f5dde68"}},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"trainer_base = Trainer(model,\n                  training_args_base,\n                  train_dataset=DATASETS['train'],\n                  eval_dataset=DATASETS['validation'],\n                  tokenizer=tokenizer,\n                  compute_metrics=compute_metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T14:28:45.424169Z","iopub.execute_input":"2024-12-16T14:28:45.424754Z","iopub.status.idle":"2024-12-16T14:28:46.115699Z","shell.execute_reply.started":"2024-12-16T14:28:45.424703Z","shell.execute_reply":"2024-12-16T14:28:46.114764Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"torch.cuda.empty_cache()\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\n# 16/12/2024\ntrainer_base.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T14:28:47.517280Z","iopub.execute_input":"2024-12-16T14:28:47.517888Z","iopub.status.idle":"2024-12-16T14:55:38.321431Z","shell.execute_reply.started":"2024-12-16T14:28:47.517853Z","shell.execute_reply":"2024-12-16T14:55:38.320295Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='130' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [130/130 26:38, Epoch 4/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n      <th>Exact Match</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>2.537400</td>\n      <td>1.784241</td>\n      <td>0.844313</td>\n      <td>0.652000</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.595600</td>\n      <td>1.680552</td>\n      <td>0.834757</td>\n      <td>0.647200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=130, training_loss=1.9172415219820462, metrics={'train_runtime': 1610.3232, 'train_samples_per_second': 15.525, 'train_steps_per_second': 0.081, 'total_flos': 4879021147324416.0, 'train_loss': 1.9172415219820462, 'epoch': 4.976076555023924})"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"\"\"\"\nSave the model\n\"\"\"\ntrainer_base.save_model('./mdeberta-finetuned_base_params-QA_16_12_24')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T14:57:31.494063Z","iopub.execute_input":"2024-12-16T14:57:31.494427Z","iopub.status.idle":"2024-12-16T14:57:34.381449Z","shell.execute_reply.started":"2024-12-16T14:57:31.494394Z","shell.execute_reply":"2024-12-16T14:57:34.380478Z"}},"outputs":[],"execution_count":36},{"cell_type":"markdown","source":"## Evaluate","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset(\"sberquad\")\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T14:57:36.352008Z","iopub.execute_input":"2024-12-16T14:57:36.352756Z","iopub.status.idle":"2024-12-16T14:57:37.789312Z","shell.execute_reply.started":"2024-12-16T14:57:36.352723Z","shell.execute_reply":"2024-12-16T14:57:37.788450Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 45328\n    })\n    validation: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 5036\n    })\n    test: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 23936\n    })\n})"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"test_dataset = dataset['test'].map(\n    preprocess_examples,\n    batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T14:57:38.576157Z","iopub.execute_input":"2024-12-16T14:57:38.576982Z","iopub.status.idle":"2024-12-16T14:58:08.166462Z","shell.execute_reply.started":"2024-12-16T14:57:38.576934Z","shell.execute_reply":"2024-12-16T14:58:08.165632Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/23936 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19c8547691e54d0591abaf46a7d4f4e1"}},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"# predict + compute metrics on our test set\ntrainer_base.eval_dataset = test_dataset\ntrainer_base.evaluate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T14:58:10.705328Z","iopub.execute_input":"2024-12-16T14:58:10.705766Z","iopub.status.idle":"2024-12-16T15:07:33.419622Z","shell.execute_reply.started":"2024-12-16T14:58:10.705728Z","shell.execute_reply":"2024-12-16T15:07:33.418810Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='998' max='998' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [998/998 09:12]\n    </div>\n    "},"metadata":{}},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 7.6507954597473145,\n 'eval_f1': 0.037796401565128666,\n 'eval_exact_match': 0.0,\n 'eval_runtime': 562.6968,\n 'eval_samples_per_second': 42.538,\n 'eval_steps_per_second': 1.774,\n 'epoch': 4.976076555023924}"},"metadata":{}}],"execution_count":39},{"cell_type":"markdown","source":"## 3.3 Getting the best hyperparameters by optuna\n\n`CREATE OPTUNA STUDY`","metadata":{}},{"cell_type":"code","source":"# hyperparameters - https://python-bloggers.com/2022/08/hyperparameter-tuning-a-transformer-with-optuna/\nLR_MIN = 4e-5 # Learning rate minimum and maximum (ceiling) named LR_MIN and LR_CEIL\nLR_CEIL = 0.01\nWD_MIN = 4e-5 # Weight decay minimum and ceilling named WD_MIN and WD_CEIL\nWD_CEIL = 0.01\nWR_MIN = 0.01\nWR_CEIL = 0.2\nMIN_GRAD_ACC = 1\nMAX_GRAD_ACC = 5\nMIN_EPOCHS = 2 # Minimum and maximum epochs named MIN_EPOCHS and MAX_EPOCHS\nMAX_EPOCHS = 5\nPER_DEVICE_EVAL_BATCH = 10 # per device evaluation batch sizes for the training and evaluation sets\nPER_DEVICE_TRAIN_BATCH = 10\nNUM_TRIALS = 3 # number of Optuna trials to implement – incrementing this will perform multiple hyperparameter trials for each individual permutation and setting\nSAVE_DIR = 'optuna-test' # SAVE_DIR is the name of the folder to save it to\nNAME_OF_MODEL = 'optuna_bp' # NAME_OF_MODEL is what I want to call my serialised and fine tuned transformer network","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:38:13.065237Z","iopub.execute_input":"2024-12-17T07:38:13.065611Z","iopub.status.idle":"2024-12-17T07:38:13.071168Z","shell.execute_reply.started":"2024-12-17T07:38:13.065581Z","shell.execute_reply":"2024-12-17T07:38:13.070299Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"model = AutoModelForQuestionAnswering.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:38:15.218071Z","iopub.execute_input":"2024-12-17T07:38:15.219206Z","iopub.status.idle":"2024-12-17T07:38:20.387763Z","shell.execute_reply.started":"2024-12-17T07:38:15.219158Z","shell.execute_reply":"2024-12-17T07:38:20.387082Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/879 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ea650ecd660468eb4c7c662d695372e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e615de7ddb44f1faf8ba203444615f3"}},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.cuda.empty_cache()\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:38:20.389609Z","iopub.execute_input":"2024-12-17T07:38:20.390283Z","iopub.status.idle":"2024-12-17T07:38:20.977368Z","shell.execute_reply.started":"2024-12-17T07:38:20.390238Z","shell.execute_reply":"2024-12-17T07:38:20.976301Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"DebertaV2ForQuestionAnswering(\n  (deberta): DebertaV2Model(\n    (embeddings): DebertaV2Embeddings(\n      (word_embeddings): Embedding(251000, 768, padding_idx=0)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n      (dropout): StableDropout()\n    )\n    (encoder): DebertaV2Encoder(\n      (layer): ModuleList(\n        (0-11): 12 x DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): StableDropout()\n              (dropout): StableDropout()\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): StableDropout()\n          )\n        )\n      )\n      (rel_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n    )\n  )\n  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n)"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"def objective(trial: optuna.Trial):     \n    model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n    \n    training_args = TrainingArguments(         \n        output_dir=SAVE_DIR, \n        optim=\"adamw_torch\",\n        learning_rate=trial.suggest_loguniform('learning_rate', low=LR_MIN, high=LR_CEIL),         \n        weight_decay=trial.suggest_loguniform('weight_decay', WD_MIN, WD_CEIL),\n        warmup_ratio=trial.suggest_loguniform('warmup_ratio', WR_MIN, WR_CEIL),\n        gradient_accumulation_steps=trial.suggest_int('gradient_accumulation_steps', low = MIN_GRAD_ACC,high = MAX_GRAD_ACC),\n        num_train_epochs=trial.suggest_int('num_train_epochs', low = MIN_EPOCHS,high = MAX_EPOCHS),         \n        per_device_train_batch_size=PER_DEVICE_TRAIN_BATCH,         \n        per_device_eval_batch_size=PER_DEVICE_EVAL_BATCH,\n        seed = RANDOM_SEED,\n        lr_scheduler_type='cosine')     \n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=DATASETS_for_optuna['train'],\n        eval_dataset=DATASETS_for_optuna['validation'],\n        compute_metrics=compute_metrics_for_optuna)      \n    \n    result = trainer.train()\n    \n    return result.training_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:38:20.978496Z","iopub.execute_input":"2024-12-17T07:38:20.978811Z","iopub.status.idle":"2024-12-17T07:38:20.985713Z","shell.execute_reply.started":"2024-12-17T07:38:20.978781Z","shell.execute_reply":"2024-12-17T07:38:20.984267Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"def print_custom(text):\n    print('\\n')\n    print(text)\n    print('-'*100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:38:20.987976Z","iopub.execute_input":"2024-12-17T07:38:20.988340Z","iopub.status.idle":"2024-12-17T07:38:21.062689Z","shell.execute_reply.started":"2024-12-17T07:38:20.988310Z","shell.execute_reply":"2024-12-17T07:38:21.061909Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"print_custom('Triggering Optuna study')\nstudy = optuna.create_study(study_name='hp-search-electra', direction='minimize') \nstudy.optimize(func=objective, n_trials=NUM_TRIALS)\n\n# This can be used to train the final model. Passed through using kwargs into the model\nprint_custom('Finding study best parameters')\nbest_lr = float(study.best_params['learning_rate'])\nbest_weight_decay = float(study.best_params['weight_decay'])\nbest_warmup_ratio = float(study.best_params['warmup_ratio'])\nbest_gradient_accumulation_steps = int(study.best_params['gradient_accumulation_steps'])\nbest_epoch = int(study.best_params['num_train_epochs'])\n\nprint_custom('Extract best study params')\nprint(f'The best learning rate is: {best_lr}')\nprint(f'The best weight decay is: {best_weight_decay}')\nprint(f'The best warmup ratio is: {best_warmup_ratio}')\nprint(f'The best gradient accumulation step is : {best_gradient_accumulation_steps}')\nprint(f'The best epoch is : {best_epoch}')\n\nprint_custom('Create dictionary of the best hyperparameters')\nbest_hp_dict = {\n    'best_learning_rate': best_lr,\n    'best_weight_decay': best_weight_decay,\n    'best_warmup_ratio': best_warmup_ratio,\n    'best_gradient_accumulation_steps': best_gradient_accumulation_steps,\n    'best_epoch': best_epoch\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:38:21.063711Z","iopub.execute_input":"2024-12-17T07:38:21.064019Z","iopub.status.idle":"2024-12-17T07:45:28.631605Z","shell.execute_reply.started":"2024-12-17T07:38:21.063984Z","shell.execute_reply":"2024-12-17T07:45:28.630357Z"}},"outputs":[{"name":"stderr","text":"[I 2024-12-17 07:38:21,071] A new study created in memory with name: hp-search-electra\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"\n\nTriggering Optuna study\n----------------------------------------------------------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [25/25 02:28, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"[I 2024-12-17 07:40:58,623] Trial 0 finished with value: 1.7351736450195312 and parameters: {'learning_rate': 8.224316278391225e-05, 'weight_decay': 0.0016061074719990397, 'warmup_ratio': 0.013727255778614706, 'gradient_accumulation_steps': 5, 'num_train_epochs': 5}. Best is trial 0 with value: 1.7351736450195312.\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [100/100 02:18, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"[I 2024-12-17 07:43:19,062] Trial 1 finished with value: 5.449199829101563 and parameters: {'learning_rate': 0.00230422656093221, 'weight_decay': 0.006406776712275002, 'warmup_ratio': 0.017113996598093775, 'gradient_accumulation_steps': 1, 'num_train_epochs': 4}. Best is trial 0 with value: 1.7351736450195312.\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [32/32 02:04, Epoch 3/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"[I 2024-12-17 07:45:28,625] Trial 2 finished with value: 1.917277216911316 and parameters: {'learning_rate': 5.2596423028803626e-05, 'weight_decay': 9.040727861254416e-05, 'warmup_ratio': 0.044475576825465414, 'gradient_accumulation_steps': 3, 'num_train_epochs': 4}. Best is trial 0 with value: 1.7351736450195312.\n","output_type":"stream"},{"name":"stdout","text":"\n\nFinding study best parameters\n----------------------------------------------------------------------------------------------------\n\n\nExtract best study params\n----------------------------------------------------------------------------------------------------\nThe best learning rate is: 8.224316278391225e-05\nThe best weight decay is: 0.0016061074719990397\nThe best warmup ratio is: 0.013727255778614706\nThe best gradient accumulation step is : 5\nThe best epoch is : 5\n\n\nCreate dictionary of the best hyperparameters\n----------------------------------------------------------------------------------------------------\n","output_type":"stream"}],"execution_count":35},{"cell_type":"markdown","source":"## 3.4 Training model with the best hyperparameters","metadata":{}},{"cell_type":"code","source":"training_args_bp = TrainingArguments(\"mdeberta-squad-best-params\",\n                                     evaluation_strategy=\"steps\",\n                                     eval_steps=100,\n                                     logging_steps=100,\n                                     # save_steps=100,\n                                     optim=\"adamw_torch\",\n                                     learning_rate=best_lr,\n                                     per_device_train_batch_size=PER_DEVICE_TRAIN_BATCH,\n                                     per_device_eval_batch_size=PER_DEVICE_EVAL_BATCH,\n                                     warmup_steps=50,\n                                     seed = RANDOM_SEED,\n                                     lr_scheduler_type='cosine',\n                                     save_strategy = \"no\", # to avoid saving anything and save the final model once training is done with .save_model()\n                                     fp16=True, #reduce the memory footprint - If you have an error as No space left on device during training&saving results\n                                     weight_decay=best_weight_decay,\n                                     warmup_ratio=best_warmup_ratio,\n                                     gradient_accumulation_steps=best_gradient_accumulation_steps,\n                                     num_train_epochs=best_epoch)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:45:28.634406Z","iopub.execute_input":"2024-12-17T07:45:28.634853Z","iopub.status.idle":"2024-12-17T07:45:28.683818Z","shell.execute_reply.started":"2024-12-17T07:45:28.634788Z","shell.execute_reply":"2024-12-17T07:45:28.682852Z"}},"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"trainer_bp = Trainer(model,\n                  training_args_bp,\n                  train_dataset=DATASETS['train'],\n                  eval_dataset=DATASETS['validation'],\n                  tokenizer=tokenizer,\n                  compute_metrics=compute_metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:45:28.685385Z","iopub.execute_input":"2024-12-17T07:45:28.687285Z","iopub.status.idle":"2024-12-17T07:45:28.706310Z","shell.execute_reply.started":"2024-12-17T07:45:28.687252Z","shell.execute_reply":"2024-12-17T07:45:28.705396Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"torch.cuda.empty_cache()\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\n# 17/12/2024\ntrainer_bp.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:45:41.540686Z","iopub.execute_input":"2024-12-17T07:45:41.541107Z","iopub.status.idle":"2024-12-17T08:12:58.729796Z","shell.execute_reply.started":"2024-12-17T07:45:41.541072Z","shell.execute_reply":"2024-12-17T08:12:58.729004Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [250/250 27:10, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n      <th>Exact Match</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>1.976200</td>\n      <td>1.641488</td>\n      <td>0.837407</td>\n      <td>0.641600</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.127900</td>\n      <td>1.904699</td>\n      <td>0.758720</td>\n      <td>0.561600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=250, training_loss=1.4074424591064454, metrics={'train_runtime': 1636.472, 'train_samples_per_second': 15.277, 'train_steps_per_second': 0.153, 'total_flos': 4899402662400000.0, 'train_loss': 1.4074424591064454, 'epoch': 5.0})"},"metadata":{}}],"execution_count":38},{"cell_type":"markdown","source":"**Some observations**:\n* Metrics reduction occurs due to the choice of hyperparameters based on a very small sample of the dataset","metadata":{}},{"cell_type":"code","source":"\"\"\"\nSave the model\n\"\"\"\ntrainer_bp.save_model('./mdeberta-finetuned-best_params-QA_17_12_24')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T08:13:16.174226Z","iopub.execute_input":"2024-12-17T08:13:16.175078Z","iopub.status.idle":"2024-12-17T08:13:19.228469Z","shell.execute_reply.started":"2024-12-17T08:13:16.175044Z","shell.execute_reply":"2024-12-17T08:13:19.227709Z"}},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":"# 4. Evaluate","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset(\"sberquad\")\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T08:13:22.011999Z","iopub.execute_input":"2024-12-17T08:13:22.013062Z","iopub.status.idle":"2024-12-17T08:13:23.627815Z","shell.execute_reply.started":"2024-12-17T08:13:22.013008Z","shell.execute_reply":"2024-12-17T08:13:23.627028Z"}},"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 45328\n    })\n    validation: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 5036\n    })\n    test: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 23936\n    })\n})"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"# dataset_test_part = dataset[\"test\"].train_test_split()\n# dataset_test_part['test']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T17:23:17.158334Z","iopub.status.idle":"2024-12-16T17:23:17.158602Z","shell.execute_reply.started":"2024-12-16T17:23:17.158473Z","shell.execute_reply":"2024-12-16T17:23:17.158486Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_dataset = dataset['test'].map(\n    preprocess_examples,\n    batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T08:13:24.266175Z","iopub.execute_input":"2024-12-17T08:13:24.266879Z","iopub.status.idle":"2024-12-17T08:13:56.411667Z","shell.execute_reply.started":"2024-12-17T08:13:24.266844Z","shell.execute_reply":"2024-12-17T08:13:56.410611Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/23936 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91a7289fca1c48e7ac61203cf0c9cd58"}},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"# predict + compute metrics on our test set\ntrainer_bp.eval_dataset = test_dataset\ntrainer_bp.evaluate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T08:13:56.413152Z","iopub.execute_input":"2024-12-17T08:13:56.413421Z","iopub.status.idle":"2024-12-17T08:23:14.132058Z","shell.execute_reply.started":"2024-12-17T08:13:56.413394Z","shell.execute_reply":"2024-12-17T08:23:14.131146Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1197' max='1197' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1197/1197 09:07]\n    </div>\n    "},"metadata":{}},{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 9.664545059204102,\n 'eval_f1': 0.038647634497779845,\n 'eval_exact_match': 0.0,\n 'eval_runtime': 557.6996,\n 'eval_samples_per_second': 42.919,\n 'eval_steps_per_second': 2.146,\n 'epoch': 5.0}"},"metadata":{}}],"execution_count":42},{"cell_type":"markdown","source":"**Some observations**:\n* As you can see, there is no any rapidly changes between metrics as the result of training model based on the base hyperparams VS hyperparams getting from automatic hyperparameter optimizations.\n* Moreover loss and metric values are not stable (and worse than at the first trainig experiments) during training based on the best hyperparams because I got only small part of the dataset for that.\n* It will be better to use more data for getting best hyperparams and training model if you have enough resources (time and GPU/CPU memory).\n\nBut in this case I want to check only:\n* how does optuna work for transformer model\n* baseline value of f_1 score and exact_match\n\nAnd we get it!","metadata":{}}]}