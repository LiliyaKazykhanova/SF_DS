{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project-6: Transformers in production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case Description**\n",
    "\n",
    "In this notebook we will reduce model size by distillation and quantization methods\n",
    "\n",
    "**Task**\n",
    "Check metric results on test data for fine-tuning BERT model before and after applying Distillation & Quantification methods.\n",
    "\n",
    "**Dataset**:\n",
    "[AG news dataset](https://huggingface.co/datasets/fancyzhx/ag_news)\n",
    "\n",
    "**ML Task**: Model compression via distillation and quantization\n",
    "\n",
    "Training on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Install and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T15:54:54.312290Z",
     "iopub.status.busy": "2025-01-29T15:54:54.311986Z",
     "iopub.status.idle": "2025-01-29T15:55:05.520622Z",
     "shell.execute_reply": "2025-01-29T15:55:05.519684Z",
     "shell.execute_reply.started": "2025-01-29T15:54:54.312264Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers # the huggingface library containing the general-purpose architectures for NLP\n",
    "!pip install datasets # the huggingface library containing datasets and evaluation metrics for NLP\n",
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T15:55:05.522038Z",
     "iopub.status.busy": "2025-01-29T15:55:05.521775Z",
     "iopub.status.idle": "2025-01-29T15:55:21.988678Z",
     "shell.execute_reply": "2025-01-29T15:55:21.987797Z",
     "shell.execute_reply.started": "2025-01-29T15:55:05.522019Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Libs for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "\n",
    "# pytorch libraries\n",
    "import torch\n",
    "import evaluate\n",
    "import transformers\n",
    "from transformers import DataCollatorWithPadding, AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer, pipeline\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from evaluate import evaluator\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T15:55:21.991020Z",
     "iopub.status.busy": "2025-01-29T15:55:21.990406Z",
     "iopub.status.idle": "2025-01-29T15:55:22.003539Z",
     "shell.execute_reply": "2025-01-29T15:55:22.002722Z",
     "shell.execute_reply.started": "2025-01-29T15:55:21.990997Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Fixing RANDOM_SEED to make experiment repetable\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Set random seeds\n",
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Helper function for reproducible behavior to set the seed in ``random``, ``numpy``, ``torch`` and/or ``tf`` (if\n",
    "    installed).\n",
    "\n",
    "    Args:\n",
    "        seed (:obj:`int`): The seed to set.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "#     tf.random.set_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    \n",
    "set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T15:55:22.004854Z",
     "iopub.status.busy": "2025-01-29T15:55:22.004570Z",
     "iopub.status.idle": "2025-01-29T15:55:23.127226Z",
     "shell.execute_reply": "2025-01-29T15:55:23.126097Z",
     "shell.execute_reply.started": "2025-01-29T15:55:22.004823Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Fixing package versions to make experiment repetable\n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T15:55:23.128471Z",
     "iopub.status.busy": "2025-01-29T15:55:23.128229Z",
     "iopub.status.idle": "2025-01-29T15:55:23.210352Z",
     "shell.execute_reply": "2025-01-29T15:55:23.209535Z",
     "shell.execute_reply.started": "2025-01-29T15:55:23.128451Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# If we have a GPU available, we'll set our device to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Loading: dataset exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AG News (AG's News Corpus) is a subdataset of AG's corpus of news articles constructed by assembling titles (labels) and description fields of articles from the 4 largest classes (“World”, “Sports”, “Business”, “Sci/Tech”) of AG's Corpus.\n",
    "\n",
    "The AG News contains 120,000 training and 7,600 test samples per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T15:55:23.211530Z",
     "iopub.status.busy": "2025-01-29T15:55:23.211261Z",
     "iopub.status.idle": "2025-01-29T15:55:26.066692Z",
     "shell.execute_reply": "2025-01-29T15:55:26.065885Z",
     "shell.execute_reply.started": "2025-01-29T15:55:23.211509Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e439d8325ac49339fcabb460fdd5116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d9da86fa8f54268a3f592346a103078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/18.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b78bdcdb699740b99dfe932bc1075716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/1.23M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476fb1f42e1247f9b1e42de97057701d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "993275d784cb46f9b79575f2e8b839e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 120000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 7600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the AG news dataset - https://huggingface.co/datasets/fancyzhx/ag_news\n",
    "dataset_ag = load_dataset(\"fancyzhx/ag_news\")\n",
    "dataset_ag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several important fields here:\n",
    "\n",
    "* **text**: description fields of articles.\n",
    "* **label**: 4 clasess of articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T15:55:26.067648Z",
     "iopub.status.busy": "2025-01-29T15:55:26.067448Z",
     "iopub.status.idle": "2025-01-29T15:55:26.072685Z",
     "shell.execute_reply": "2025-01-29T15:55:26.071879Z",
     "shell.execute_reply.started": "2025-01-29T15:55:26.067629Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  2\n",
      "\n",
      "Text:  Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private investment firm Carlyle Group,\\which has a reputation for making well-timed and occasionally\\controversial plays in the defense industry, has quietly placed\\its bets on another part of the market.\n"
     ]
    }
   ],
   "source": [
    "# Look at the examples in train dataset\n",
    "print(\"Label: \", dataset_ag[\"train\"][1][\"label\"])\n",
    "print(\"\\nText: \", dataset_ag[\"train\"][1][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AG's news topic classification dataset is constructed by choosing 4 largest classes from the original corpus. Each class contains 30,000 training samples and 1,900 testing samples. The total number of training samples is 120,000 and testing 7,600.\n",
    "\n",
    "It means that as a key metric I can choose **accuracy_score** because our data is balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess dataset\n",
    "\n",
    "* Create train/validation/ test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train/ validation / test sets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T15:55:26.075260Z",
     "iopub.status.busy": "2025-01-29T15:55:26.075025Z",
     "iopub.status.idle": "2025-01-29T15:55:26.124495Z",
     "shell.execute_reply": "2025-01-29T15:55:26.123648Z",
     "shell.execute_reply.started": "2025-01-29T15:55:26.075242Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 108000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 12000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create a validation set (10%) for finding the model with best generalizability\n",
    "\"\"\"\n",
    "train_val_dataset = dataset_ag[\"train\"].train_test_split(test_size=0.1, seed=RANDOM_SEED)\n",
    "train_val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T15:55:26.125883Z",
     "iopub.status.busy": "2025-01-29T15:55:26.125623Z",
     "iopub.status.idle": "2025-01-29T15:55:26.131062Z",
     "shell.execute_reply": "2025-01-29T15:55:26.130374Z",
     "shell.execute_reply.started": "2025-01-29T15:55:26.125862Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 108000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 12000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 7600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create datasets for fine-tuning\n",
    "\"\"\"\n",
    "datasets = DatasetDict({\n",
    "    'train': train_val_dataset['train'],\n",
    "    'validation': train_val_dataset['test'],\n",
    "    'test': dataset_ag['test']\n",
    "})\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T15:55:26.132005Z",
     "iopub.status.busy": "2025-01-29T15:55:26.131750Z",
     "iopub.status.idle": "2025-01-29T15:55:26.149638Z",
     "shell.execute_reply": "2025-01-29T15:55:26.148822Z",
     "shell.execute_reply.started": "2025-01-29T15:55:26.131975Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 4\n",
      "id2label: {0: 'World', 1: 'Sports', 2: 'Business', 3: 'Sci/Tech'}\n",
      "label2id: {'World': 0, 'Sports': 1, 'Business': 2, 'Sci/Tech': 3}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Get class label information from dataset\n",
    "\"\"\"\n",
    "num_labels = datasets[\"train\"].features[\"label\"].num_classes\n",
    "\n",
    "id2label = {}\n",
    "label2id = {}\n",
    "\n",
    "for label_id, label in enumerate(datasets[\"train\"].features[\"label\"].names):\n",
    "    id2label[label_id] = label\n",
    "    label2id[label] = label_id\n",
    "\n",
    "print(f\"Number of labels: {num_labels}\")\n",
    "print(f\"id2label: {id2label}\")\n",
    "print(f\"label2id: {label2id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T15:55:26.150718Z",
     "iopub.status.busy": "2025-01-29T15:55:26.150435Z",
     "iopub.status.idle": "2025-01-29T15:55:26.165690Z",
     "shell.execute_reply": "2025-01-29T15:55:26.164862Z",
     "shell.execute_reply.started": "2025-01-29T15:55:26.150689Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[83810, 14592, 3278]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get random integers in the range of 0 to train_dataset_length\n",
    "example_indices = [random.randrange(len(datasets[\"train\"])) for _ in range(3)]\n",
    "example_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T15:55:26.166673Z",
     "iopub.status.busy": "2025-01-29T15:55:26.166422Z",
     "iopub.status.idle": "2025-01-29T15:55:29.775396Z",
     "shell.execute_reply": "2025-01-29T15:55:29.774505Z",
     "shell.execute_reply.started": "2025-01-29T15:55:26.166653Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT[83810]: Hopes fade for China mine victims Rescuers express mounting fears for 86 people still missing after a gas explosion in a China coal mine killed 62.\n",
      "LABEL[83810]: World (0)\n",
      "\n",
      "TEXT[14592]: Notebook: Breeders #39; Cup gives title hope to several The landscape has changed since Smarty Jones #39; meteoric rise from obscurity to stardom last spring, when the colt from Pennsylvania appeared to be \n",
      "LABEL[14592]: Sports (1)\n",
      "\n",
      "TEXT[3278]: Max Table size in MySQL \\\\It turns out that MySQL  has a terrible upper limit on the max MyISAM table\\size.  It appears that innodb doesn't have this problem.\\\\Jeremy talks about it over on his blog \\\\\"When this happens, the first reaction I hear is \"You never told me that MySQL\\has a 4GB limit! What am I going to do?\" Amusingly, I usually do describe the\\limit when I discuss the possibility of using MySQL with various groups--they\\often forget or underestimate the impact it will have. Putting that aside, the\\problem is easily fixed, as that page explains. You simply need to run an ALTER\\TABLE command.\"\\\\\"And you'll need to wait. That ALTER TABLE is going to take some time. Really.\"\\\\Of course Jeremey warns us that ...\\\\\n",
      "LABEL[3278]: Sci/Tech (3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in example_indices:\n",
    "    text = datasets['train']['text'][i]\n",
    "    label_id = datasets['train']['label'][i]\n",
    "    label = id2label[label_id]\n",
    "    \n",
    "    print(f\"TEXT[{i}]: {text}\")\n",
    "    print(f\"LABEL[{i}]: {label} ({label_id})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model training\n",
    "\n",
    "This part consists of 3 examples of model training:\n",
    "- fine-tuned BERT base model\n",
    "- distilled BERT model (DistilBert, TinyBERT, MiniLM)\n",
    "- quantized BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T15:55:29.776655Z",
     "iopub.status.busy": "2025-01-29T15:55:29.776355Z",
     "iopub.status.idle": "2025-01-29T15:55:29.780579Z",
     "shell.execute_reply": "2025-01-29T15:55:29.779897Z",
     "shell.execute_reply.started": "2025-01-29T15:55:29.776626Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to get Model size\n",
    "\"\"\"\n",
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), 'temp.p')\n",
    "    print('Size (MB): ',\n",
    "         np.round(os.path.getsize('temp.p')/1e6, 2))\n",
    "    os.remove('temp.p')\n",
    "\n",
    "# def get_layer_sizes(model):\n",
    "#     layer_sizes = {}\n",
    "#     total_size = 0\n",
    "\n",
    "#     for name, param in model.named_parameters():\n",
    "#         layer_size = param.numel() * param.element_size()  # numel() returns the number of elements, element_size() returns the size in bytes of each element\n",
    "#         total_size += layer_size\n",
    "#         layer_sizes[name] = (param.numel(), layer_size, param.dtype)\n",
    "\n",
    "#     return layer_sizes, total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T15:55:29.781859Z",
     "iopub.status.busy": "2025-01-29T15:55:29.781493Z",
     "iopub.status.idle": "2025-01-29T15:55:29.796674Z",
     "shell.execute_reply": "2025-01-29T15:55:29.796065Z",
     "shell.execute_reply.started": "2025-01-29T15:55:29.781827Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def tokenize(dataset,tokenizer):\n",
    "    \"\"\"\n",
    "    Function to use map to tokenize entire dataset and batch building\n",
    "    \"\"\"\n",
    "    # tokenize and truncate dataset by batch, while removing unused column\n",
    "    tokenized_dataset = dataset.map(lambda x: tokenizer(x[\"text\"], truncation=True),\n",
    "                                     batched=True,\n",
    "                                     remove_columns=[\"text\"])\n",
    "\n",
    "    # rename for multiclass fine-tuning\n",
    "    tokenized_ds = tokenized_dataset.rename_column(\"label\", \"labels\")\n",
    "\n",
    "    # set format to pytorch\n",
    "    tokenized_ds.set_format(type=\"torch\")\n",
    "\n",
    "    return tokenized_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Fine-tuning BERT base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T15:55:29.797831Z",
     "iopub.status.busy": "2025-01-29T15:55:29.797532Z",
     "iopub.status.idle": "2025-01-29T15:55:30.961835Z",
     "shell.execute_reply": "2025-01-29T15:55:30.961155Z",
     "shell.execute_reply.started": "2025-01-29T15:55:29.797785Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1542a197b3b34dc38253348225ac0448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "439805be5dfa4eb6afeccc67b08836cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc4ba16f5a5435d8339fb88f4463961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f564cffb71154218a2a5b10477284ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Loading the tokenizer corresponding to a pretrained BERT model.\n",
    "Using the same tokenizer as the pretrained model is important because I want to make sure the text is split in the same way.\n",
    "\"\"\"\n",
    "# Load the pre-trained BERT model and tokenizer - get fast BERT tokenizer\n",
    "model_checkpoint = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T15:55:30.962766Z",
     "iopub.status.busy": "2025-01-29T15:55:30.962551Z",
     "iopub.status.idle": "2025-01-29T15:55:30.970691Z",
     "shell.execute_reply": "2025-01-29T15:55:30.970044Z",
     "shell.execute_reply.started": "2025-01-29T15:55:30.962749Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 13905, 1998, 4963, 1999, 2235, 2845, 2237, 2044, 6859, 2022, 14540, 2319, 1010, 3607, 1006, 26665, 1007, 1011, 1996, 4288, 1997, 2062, 2084, 13710, 2336, 1010, 3008, 1998, 5089, 2076, 1996, 6703, 2203, 2000, 1037, 5187, 1011, 3178, 2082, 6859, 2187, 4510, 1037, 2155, 22154, 1999, 1996, 2235, 2845, 2237, 1997, 2022, 14540, 2319, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Call tokenizer on the first row of text in the dataset\n",
    "\"\"\"\n",
    "tokenizer(datasets[\"train\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tokenizer returns a dictionary with three items:\n",
    "\n",
    "* **input_ids**: the numbers representing the tokens in the text.\n",
    "* **token_type_ids**: indicates which sequence a token belongs to if there is more than one sequence.\n",
    "* **attention_mask**: indicates whether a token should be masked or not.\n",
    "\n",
    "These values are actually the model inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T15:55:30.971857Z",
     "iopub.status.busy": "2025-01-29T15:55:30.971571Z",
     "iopub.status.idle": "2025-01-29T15:55:57.486887Z",
     "shell.execute_reply": "2025-01-29T15:55:57.486051Z",
     "shell.execute_reply.started": "2025-01-29T15:55:30.971829Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b028720e9c487cb5a28e8c4cd5f169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/108000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3d5a3baa63431088f87005b2fe8187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bcf9ade5286440caaa16a4834ac83c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = tokenize(datasets,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T15:55:57.488114Z",
     "iopub.status.busy": "2025-01-29T15:55:57.487795Z",
     "iopub.status.idle": "2025-01-29T15:55:57.492944Z",
     "shell.execute_reply": "2025-01-29T15:55:57.492291Z",
     "shell.execute_reply.started": "2025-01-29T15:55:57.488084Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 108000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 12000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 7600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 columns:\n",
    "\n",
    "* **labels**: the true class label that corresponds to this news\n",
    "* **input_ids**: the token ids based on the tokenizer\n",
    "* **token_type_ids**: the binary mask identifying the two types of sequence in the model\n",
    "* **attention_mask**: the attention boolean map of token ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T15:55:57.493956Z",
     "iopub.status.busy": "2025-01-29T15:55:57.493691Z",
     "iopub.status.idle": "2025-01-29T15:55:57.513319Z",
     "shell.execute_reply": "2025-01-29T15:55:57.512678Z",
     "shell.execute_reply.started": "2025-01-29T15:55:57.493936Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Apply dynamic padding strategy to pad our texts\n",
    "Instead of padding the whole dataset to the longest sequence, we will pad to the longest sequence in the current batch\n",
    "\n",
    "In order to use dynamic padding in combination with the Trainer:\n",
    "- firstly, specifying truncation=True when preprocessing the dataset,\n",
    "- after using the DataCollatorWithPadding when defining the data loaders, which will dynamically pad the batches\n",
    "\"\"\"\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T15:55:57.514379Z",
     "iopub.status.busy": "2025-01-29T15:55:57.514151Z",
     "iopub.status.idle": "2025-01-29T15:56:00.589073Z",
     "shell.execute_reply": "2025-01-29T15:56:00.588062Z",
     "shell.execute_reply.started": "2025-01-29T15:55:57.514361Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad7190e5859d490c8bd8008281ab66f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T15:56:00.590263Z",
     "iopub.status.busy": "2025-01-29T15:56:00.589964Z",
     "iopub.status.idle": "2025-01-29T15:56:01.311265Z",
     "shell.execute_reply": "2025-01-29T15:56:01.310442Z",
     "shell.execute_reply.started": "2025-01-29T15:56:00.590232Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB):  438.01\n"
     ]
    }
   ],
   "source": [
    "print_size_of_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T15:56:08.813720Z",
     "iopub.status.busy": "2025-01-29T15:56:08.813422Z",
     "iopub.status.idle": "2025-01-29T15:56:08.986494Z",
     "shell.execute_reply": "2025-01-29T15:56:08.985884Z",
     "shell.execute_reply.started": "2025-01-29T15:56:08.813696Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "# Set values for model and train\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_bert\",\n",
    "    # important as the standard setting of 500 creates too much data\n",
    "    save_strategy = 'epoch',\n",
    "    optim=\"adamw_torch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    group_by_length=True # grouping together samples of the same length - smart batching\n",
    ")\n",
    "\n",
    "trainer_ft_bert = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T15:56:09.682619Z",
     "iopub.status.busy": "2025-01-29T15:56:09.682328Z",
     "iopub.status.idle": "2025-01-29T16:13:06.771345Z",
     "shell.execute_reply": "2025-01-29T16:13:06.770375Z",
     "shell.execute_reply.started": "2025-01-29T15:56:09.682597Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3375' max='3375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3375/3375 16:14, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.348700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.232300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.206800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.198900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.187600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.177500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19min 42s, sys: 18.1 s, total: 20min\n",
      "Wall time: 16min 57s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3375, training_loss=0.21926742666739005, metrics={'train_runtime': 977.4549, 'train_samples_per_second': 110.491, 'train_steps_per_second': 3.453, 'total_flos': 3146733172058112.0, 'train_loss': 0.21926742666739005, 'epoch': 1.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 29/01/2025\n",
    "%time trainer_ft_bert.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:13:07.913203Z",
     "iopub.status.busy": "2025-01-29T16:13:07.912888Z",
     "iopub.status.idle": "2025-01-29T16:13:42.418643Z",
     "shell.execute_reply": "2025-01-29T16:13:42.417870Z",
     "shell.execute_reply.started": "2025-01-29T16:13:07.913177Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7600, 4)\n"
     ]
    }
   ],
   "source": [
    "preds_bert = trainer_ft_bert.predict(tokenized_datasets['test'])\n",
    "print(preds_bert.predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:13:42.419893Z",
     "iopub.status.busy": "2025-01-29T16:13:42.419552Z",
     "iopub.status.idle": "2025-01-29T16:13:42.440659Z",
     "shell.execute_reply": "2025-01-29T16:13:42.440012Z",
     "shell.execute_reply.started": "2025-01-29T16:13:42.419867Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7600"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the predictions into an interpretable form.\n",
    "preds_flat = [np.argmax(x) for x in preds_bert[0]]\n",
    "\n",
    "len(preds_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Metrics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:13:42.442342Z",
     "iopub.status.busy": "2025-01-29T16:13:42.442133Z",
     "iopub.status.idle": "2025-01-29T16:13:42.773628Z",
     "shell.execute_reply": "2025-01-29T16:13:42.772779Z",
     "shell.execute_reply.started": "2025-01-29T16:13:42.442324Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(tokenized_datasets['test']['labels'], preds_flat)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:13:42.774660Z",
     "iopub.status.busy": "2025-01-29T16:13:42.774454Z",
     "iopub.status.idle": "2025-01-29T16:13:42.784648Z",
     "shell.execute_reply": "2025-01-29T16:13:42.783989Z",
     "shell.execute_reply.started": "2025-01-29T16:13:42.774642Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy BERT_base: 0.941\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(tokenized_datasets['test']['labels'], preds_flat)\n",
    "\n",
    "print(f'Accuracy BERT_base: {np.round(acc, 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We get average accuracy_score **0.94** - after 1 epoch (16 minutes)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:13:42.785688Z",
     "iopub.status.busy": "2025-01-29T16:13:42.785491Z",
     "iopub.status.idle": "2025-01-29T16:13:43.851392Z",
     "shell.execute_reply": "2025-01-29T16:13:43.850681Z",
     "shell.execute_reply.started": "2025-01-29T16:13:42.785671Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Saving the model for future use\n",
    "\"\"\"\n",
    "trainer_ft_bert.save_model(\"./BERT_base-AG-NEWS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Distillation\n",
    "- DistilBert\n",
    "- TinyBERT\n",
    "- MobileBert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DistilBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:14:52.194152Z",
     "iopub.status.busy": "2025-01-29T16:14:52.193837Z",
     "iopub.status.idle": "2025-01-29T16:14:52.198349Z",
     "shell.execute_reply": "2025-01-29T16:14:52.197457Z",
     "shell.execute_reply.started": "2025-01-29T16:14:52.194128Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_checkpoint_distil = \"distilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:14:53.098806Z",
     "iopub.status.busy": "2025-01-29T16:14:53.098480Z",
     "iopub.status.idle": "2025-01-29T16:14:54.753057Z",
     "shell.execute_reply": "2025-01-29T16:14:54.752317Z",
     "shell.execute_reply.started": "2025-01-29T16:14:53.098779Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b610df77395462ab5e1f71ccb16d033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "024999a412654707aa6ac50c6e66f0e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "088a1e3b00a2471fac0f0a7be378b5b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90df6709954a4d728d3085c3cad694a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer_distil = AutoTokenizer.from_pretrained(model_checkpoint_distil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:14:54.754279Z",
     "iopub.status.busy": "2025-01-29T16:14:54.753976Z",
     "iopub.status.idle": "2025-01-29T16:15:20.125567Z",
     "shell.execute_reply": "2025-01-29T16:15:20.124958Z",
     "shell.execute_reply.started": "2025-01-29T16:14:54.754253Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f80e13d311a4f95a3710691635dfabe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/108000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f83aa0a7d71c464c949fa0467b59e54c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a3e410ad17a4519b540f833f6a01160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_ds_distil = tokenize(datasets,tokenizer_distil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:15:20.126968Z",
     "iopub.status.busy": "2025-01-29T16:15:20.126707Z",
     "iopub.status.idle": "2025-01-29T16:15:20.130268Z",
     "shell.execute_reply": "2025-01-29T16:15:20.129620Z",
     "shell.execute_reply.started": "2025-01-29T16:15:20.126947Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Setting up the Data Collator object\n",
    "- The data collator is what will be responsible for the batches that we will be using to train the model (batch training)\n",
    "- It will be of the same type of the data that's being given to it (In this case, Input IDs, Attention Mask, and such...)\n",
    "\"\"\"\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer_distil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:15:20.131402Z",
     "iopub.status.busy": "2025-01-29T16:15:20.131123Z",
     "iopub.status.idle": "2025-01-29T16:15:21.731574Z",
     "shell.execute_reply": "2025-01-29T16:15:21.730883Z",
     "shell.execute_reply.started": "2025-01-29T16:15:20.131375Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ddd3ae451a4989a5faa6867986ac7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Loading in the HuggingFace Transformer Model\n",
    "model_distil = AutoModelForSequenceClassification.from_pretrained(model_checkpoint_distil, num_labels=4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:15:21.732596Z",
     "iopub.status.busy": "2025-01-29T16:15:21.732387Z",
     "iopub.status.idle": "2025-01-29T16:15:22.219527Z",
     "shell.execute_reply": "2025-01-29T16:15:22.218694Z",
     "shell.execute_reply.started": "2025-01-29T16:15:21.732578Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB):  267.86\n"
     ]
    }
   ],
   "source": [
    "print_size_of_model(model_distil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:15:27.796184Z",
     "iopub.status.busy": "2025-01-29T16:15:27.795871Z",
     "iopub.status.idle": "2025-01-29T16:15:27.838079Z",
     "shell.execute_reply": "2025-01-29T16:15:27.837427Z",
     "shell.execute_reply.started": "2025-01-29T16:15:27.796159Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Fine-tuning the transformer model with our data\n",
    "\"\"\"\n",
    "# Define Training Arguments and Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_distil\",\n",
    "    save_strategy = 'epoch',\n",
    "    optim=\"adamw_torch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    fp16=True,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    group_by_length=True\n",
    ")\n",
    "\n",
    "\n",
    "trainer_distil = Trainer (\n",
    "    model=model_distil,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds_distil['train'],\n",
    "    eval_dataset=tokenized_ds_distil['validation'],\n",
    "    tokenizer=tokenizer_distil,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:15:30.434610Z",
     "iopub.status.busy": "2025-01-29T16:15:30.434317Z",
     "iopub.status.idle": "2025-01-29T16:24:28.282054Z",
     "shell.execute_reply": "2025-01-29T16:24:28.281308Z",
     "shell.execute_reply.started": "2025-01-29T16:15:30.434588Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3375' max='3375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3375/3375 08:21, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.376400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.242300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.221600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.210400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.202100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.189800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 40s, sys: 11.7 s, total: 9min 52s\n",
      "Wall time: 8min 57s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3375, training_loss=0.23362364818431713, metrics={'train_runtime': 502.0003, 'train_samples_per_second': 215.139, 'train_steps_per_second': 6.723, 'total_flos': 1584300359706624.0, 'train_loss': 0.23362364818431713, 'epoch': 1.0})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#29/01/25\n",
    "%time trainer_distil.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:24:29.336199Z",
     "iopub.status.busy": "2025-01-29T16:24:29.335906Z",
     "iopub.status.idle": "2025-01-29T16:24:47.129801Z",
     "shell.execute_reply": "2025-01-29T16:24:47.129126Z",
     "shell.execute_reply.started": "2025-01-29T16:24:29.336178Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = trainer_distil.predict(tokenized_ds_distil['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:24:47.830940Z",
     "iopub.status.busy": "2025-01-29T16:24:47.830602Z",
     "iopub.status.idle": "2025-01-29T16:24:47.849768Z",
     "shell.execute_reply": "2025-01-29T16:24:47.849128Z",
     "shell.execute_reply.started": "2025-01-29T16:24:47.830914Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7600"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_flat = [np.argmax(x) for x in preds[0]]\n",
    "\n",
    "len(preds_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:24:48.619611Z",
     "iopub.status.busy": "2025-01-29T16:24:48.619295Z",
     "iopub.status.idle": "2025-01-29T16:24:48.630481Z",
     "shell.execute_reply": "2025-01-29T16:24:48.629547Z",
     "shell.execute_reply.started": "2025-01-29T16:24:48.619588Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy DistilBERT: 0.939\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(tokenized_datasets['test']['labels'], preds_flat)\n",
    "\n",
    "print(f'Accuracy DistilBERT: {np.round(acc, 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We get average fscore **0.939** - after 1 epoch (8 minutes)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:24:55.426578Z",
     "iopub.status.busy": "2025-01-29T16:24:55.426280Z",
     "iopub.status.idle": "2025-01-29T16:24:56.074225Z",
     "shell.execute_reply": "2025-01-29T16:24:56.073551Z",
     "shell.execute_reply.started": "2025-01-29T16:24:55.426556Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Saving the model for future use\n",
    "\"\"\"\n",
    "trainer_distil.save_model(\"./DistilBERT-AG-NEWS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TinyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:24:58.382544Z",
     "iopub.status.busy": "2025-01-29T16:24:58.382221Z",
     "iopub.status.idle": "2025-01-29T16:24:58.386448Z",
     "shell.execute_reply": "2025-01-29T16:24:58.385671Z",
     "shell.execute_reply.started": "2025-01-29T16:24:58.382507Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_checkpoint_tiny = \"huawei-noah/TinyBERT_General_4L_312D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:24:59.172287Z",
     "iopub.status.busy": "2025-01-29T16:24:59.172016Z",
     "iopub.status.idle": "2025-01-29T16:25:00.246912Z",
     "shell.execute_reply": "2025-01-29T16:25:00.246248Z",
     "shell.execute_reply.started": "2025-01-29T16:24:59.172265Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cac12d319754b50b419bc64b280a840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/409 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5678482e87a44b54bf58c0212dae8b4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer_tiny = AutoTokenizer.from_pretrained(model_checkpoint_tiny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:25:00.620009Z",
     "iopub.status.busy": "2025-01-29T16:25:00.619711Z",
     "iopub.status.idle": "2025-01-29T16:25:26.996831Z",
     "shell.execute_reply": "2025-01-29T16:25:26.996163Z",
     "shell.execute_reply.started": "2025-01-29T16:25:00.619985Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ccdae13cca4fa1b204d654b5feeb39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/108000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53831043e00e4b9484a33f67a92a8c98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b41fd04830424ab3dcaed07f4a8b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_ds_tiny = tokenize(datasets,tokenizer_tiny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:25:26.998096Z",
     "iopub.status.busy": "2025-01-29T16:25:26.997891Z",
     "iopub.status.idle": "2025-01-29T16:25:28.360964Z",
     "shell.execute_reply": "2025-01-29T16:25:28.360025Z",
     "shell.execute_reply.started": "2025-01-29T16:25:26.998078Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e1ca86ec5c4ac090734a5dd42332ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/62.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer_tiny)\n",
    "\n",
    "model_tiny = AutoModelForSequenceClassification.from_pretrained(model_checkpoint_tiny, num_labels=4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:25:28.362566Z",
     "iopub.status.busy": "2025-01-29T16:25:28.362316Z",
     "iopub.status.idle": "2025-01-29T16:25:28.490145Z",
     "shell.execute_reply": "2025-01-29T16:25:28.489371Z",
     "shell.execute_reply.started": "2025-01-29T16:25:28.362545Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB):  57.43\n"
     ]
    }
   ],
   "source": [
    "print_size_of_model(model_tiny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:25:34.103358Z",
     "iopub.status.busy": "2025-01-29T16:25:34.103062Z",
     "iopub.status.idle": "2025-01-29T16:25:34.143716Z",
     "shell.execute_reply": "2025-01-29T16:25:34.143096Z",
     "shell.execute_reply.started": "2025-01-29T16:25:34.103330Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "# Slightly modified training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_tiny\",\n",
    "    save_strategy = 'epoch',\n",
    "    optim=\"adamw_torch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    fp16=True,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    group_by_length=True\n",
    ")\n",
    "\n",
    "\n",
    "trainer_tiny = Trainer (\n",
    "    model=model_tiny,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds_tiny['train'],\n",
    "    eval_dataset=tokenized_ds_tiny['validation'],\n",
    "    tokenizer=tokenizer_tiny,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:25:39.458913Z",
     "iopub.status.busy": "2025-01-29T16:25:39.458565Z",
     "iopub.status.idle": "2025-01-29T16:28:34.865553Z",
     "shell.execute_reply": "2025-01-29T16:28:34.864674Z",
     "shell.execute_reply.started": "2025-01-29T16:25:39.458885Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3375' max='3375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3375/3375 02:14, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.729300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.372100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.327800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.315500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.293300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.287100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 21s, sys: 5.98 s, total: 3min 26s\n",
      "Wall time: 2min 55s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3375, training_loss=0.3750506049262153, metrics={'train_runtime': 134.264, 'train_samples_per_second': 804.385, 'train_steps_per_second': 25.137, 'total_flos': 171510224320512.0, 'train_loss': 0.3750506049262153, 'epoch': 1.0})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#29/01/25\n",
    "%time trainer_tiny.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:28:38.481146Z",
     "iopub.status.busy": "2025-01-29T16:28:38.480860Z",
     "iopub.status.idle": "2025-01-29T16:28:43.280230Z",
     "shell.execute_reply": "2025-01-29T16:28:43.279485Z",
     "shell.execute_reply.started": "2025-01-29T16:28:38.481125Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = trainer_tiny.predict(tokenized_ds_tiny['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:28:43.281515Z",
     "iopub.status.busy": "2025-01-29T16:28:43.281225Z",
     "iopub.status.idle": "2025-01-29T16:28:43.301258Z",
     "shell.execute_reply": "2025-01-29T16:28:43.300297Z",
     "shell.execute_reply.started": "2025-01-29T16:28:43.281493Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7600"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_flat = [np.argmax(x) for x in preds[0]]\n",
    "len(preds_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:28:43.303240Z",
     "iopub.status.busy": "2025-01-29T16:28:43.303019Z",
     "iopub.status.idle": "2025-01-29T16:28:43.312963Z",
     "shell.execute_reply": "2025-01-29T16:28:43.312212Z",
     "shell.execute_reply.started": "2025-01-29T16:28:43.303221Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy TinyBERT: 0.907\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(tokenized_datasets['test']['labels'], preds_flat)\n",
    "\n",
    "print(f'Accuracy TinyBERT: {np.round(acc, 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We get average fscore **0.91** - after 1 epoch (2 minutes)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:28:47.969493Z",
     "iopub.status.busy": "2025-01-29T16:28:47.969209Z",
     "iopub.status.idle": "2025-01-29T16:28:48.120616Z",
     "shell.execute_reply": "2025-01-29T16:28:48.119729Z",
     "shell.execute_reply.started": "2025-01-29T16:28:47.969471Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Saving the model for future use\n",
    "\"\"\"\n",
    "trainer_tiny.save_model(\"./TinyBERT-AG-NEWS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MiniLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:28:50.882559Z",
     "iopub.status.busy": "2025-01-29T16:28:50.882269Z",
     "iopub.status.idle": "2025-01-29T16:28:50.886393Z",
     "shell.execute_reply": "2025-01-29T16:28:50.885290Z",
     "shell.execute_reply.started": "2025-01-29T16:28:50.882535Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_checkpoint_MiniLM = \"microsoft/MiniLM-L12-H384-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:28:51.389160Z",
     "iopub.status.busy": "2025-01-29T16:28:51.388883Z",
     "iopub.status.idle": "2025-01-29T16:28:54.034551Z",
     "shell.execute_reply": "2025-01-29T16:28:54.033876Z",
     "shell.execute_reply.started": "2025-01-29T16:28:51.389137Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003ee15ac7574c74834de47b1cd7d901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e6bc6d6809439c94b5af79045dc7b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be30d057fce048a8b56c51329a15165f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "292042cfbb0949fbacef9b164a5236ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer_MiniLM = AutoTokenizer.from_pretrained(model_checkpoint_MiniLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:28:54.035855Z",
     "iopub.status.busy": "2025-01-29T16:28:54.035564Z",
     "iopub.status.idle": "2025-01-29T16:29:20.394570Z",
     "shell.execute_reply": "2025-01-29T16:29:20.393954Z",
     "shell.execute_reply.started": "2025-01-29T16:28:54.035820Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37c651c3b6994ab78f381809b11f7d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/108000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3000204ed5342628dbdf71806f78ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095fb8d138cb4f109b15bdd3eafc0ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_ds_MiniLM = tokenize(datasets, tokenizer_MiniLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:29:20.396470Z",
     "iopub.status.busy": "2025-01-29T16:29:20.396241Z",
     "iopub.status.idle": "2025-01-29T16:29:20.399762Z",
     "shell.execute_reply": "2025-01-29T16:29:20.399137Z",
     "shell.execute_reply.started": "2025-01-29T16:29:20.396449Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer_MiniLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:29:20.401079Z",
     "iopub.status.busy": "2025-01-29T16:29:20.400799Z",
     "iopub.status.idle": "2025-01-29T16:29:22.928399Z",
     "shell.execute_reply": "2025-01-29T16:29:22.927759Z",
     "shell.execute_reply.started": "2025-01-29T16:29:20.401058Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f6bfbf4189c4dc8b616ae70641df1b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/MiniLM-L12-H384-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_MiniLM = AutoModelForSequenceClassification.from_pretrained(model_checkpoint_MiniLM, num_labels=4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:29:22.929457Z",
     "iopub.status.busy": "2025-01-29T16:29:22.929174Z",
     "iopub.status.idle": "2025-01-29T16:29:23.180690Z",
     "shell.execute_reply": "2025-01-29T16:29:23.179910Z",
     "shell.execute_reply.started": "2025-01-29T16:29:22.929430Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB):  133.51\n"
     ]
    }
   ],
   "source": [
    "print_size_of_model(model_MiniLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:29:29.534586Z",
     "iopub.status.busy": "2025-01-29T16:29:29.534283Z",
     "iopub.status.idle": "2025-01-29T16:29:29.576603Z",
     "shell.execute_reply": "2025-01-29T16:29:29.575761Z",
     "shell.execute_reply.started": "2025-01-29T16:29:29.534563Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "# Define Training Arguments and Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_MiniLM\",\n",
    "    save_strategy = 'epoch',\n",
    "    optim=\"adamw_torch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    fp16=True,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    group_by_length=True\n",
    ")\n",
    "\n",
    "\n",
    "trainer_MiniLM = Trainer (\n",
    "    model=model_MiniLM,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds_MiniLM['train'],\n",
    "    eval_dataset=tokenized_ds_MiniLM['validation'],\n",
    "    tokenizer=tokenizer_MiniLM,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:29:34.467986Z",
     "iopub.status.busy": "2025-01-29T16:29:34.467654Z",
     "iopub.status.idle": "2025-01-29T16:35:40.574516Z",
     "shell.execute_reply": "2025-01-29T16:35:40.573842Z",
     "shell.execute_reply.started": "2025-01-29T16:29:34.467958Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3375' max='3375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3375/3375 05:25, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.550900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.302500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.265700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.247000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.231800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.212900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 19s, sys: 13 s, total: 7min 32s\n",
      "Wall time: 6min 6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3375, training_loss=0.2916997296368634, metrics={'train_runtime': 325.6069, 'train_samples_per_second': 331.688, 'train_steps_per_second': 10.365, 'total_flos': 787833205254144.0, 'train_loss': 0.2916997296368634, 'epoch': 1.0})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#29/01/25\n",
    "%time trainer_MiniLM.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:35:44.413175Z",
     "iopub.status.busy": "2025-01-29T16:35:44.412894Z",
     "iopub.status.idle": "2025-01-29T16:35:55.744039Z",
     "shell.execute_reply": "2025-01-29T16:35:55.743270Z",
     "shell.execute_reply.started": "2025-01-29T16:35:44.413153Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7600"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = trainer_MiniLM.predict(tokenized_ds_MiniLM['test'])\n",
    "\n",
    "preds_flat = [np.argmax(x) for x in preds[0]]\n",
    "len(preds_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:35:55.745363Z",
     "iopub.status.busy": "2025-01-29T16:35:55.745072Z",
     "iopub.status.idle": "2025-01-29T16:35:55.755429Z",
     "shell.execute_reply": "2025-01-29T16:35:55.754704Z",
     "shell.execute_reply.started": "2025-01-29T16:35:55.745341Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy MiniLM: 0.932\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(tokenized_datasets['test']['labels'], preds_flat)\n",
    "\n",
    "print(f'Accuracy MiniLM: {np.round(acc, 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We get average fscore **0.93** - after 1 epoch (5 minutes)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:35:57.961394Z",
     "iopub.status.busy": "2025-01-29T16:35:57.961095Z",
     "iopub.status.idle": "2025-01-29T16:35:58.276715Z",
     "shell.execute_reply": "2025-01-29T16:35:58.275825Z",
     "shell.execute_reply.started": "2025-01-29T16:35:57.961371Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Saving the model for future use\n",
    "\"\"\"\n",
    "trainer_MiniLM.save_model(\"./MiniLMBERT-AG-NEWS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Quantization\n",
    "`It might cause a dip in performance metrics`\n",
    "- Dynamic Quantization\n",
    "- Static Quantization\n",
    "- Quantization aware training\n",
    "Firstly, load libs for Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:36:02.316355Z",
     "iopub.status.busy": "2025-01-29T16:36:02.316075Z",
     "iopub.status.idle": "2025-01-29T16:36:39.465772Z",
     "shell.execute_reply": "2025-01-29T16:36:39.464494Z",
     "shell.execute_reply.started": "2025-01-29T16:36:02.316334Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# !pip install optimum\n",
    "# !pip install onnx\n",
    "!pip install optimum[onnxruntime-gpu]\n",
    "!pip install onnxruntime-training\n",
    "!pip install torch-ort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:36:39.467706Z",
     "iopub.status.busy": "2025-01-29T16:36:39.467402Z",
     "iopub.status.idle": "2025-01-29T16:40:04.461370Z",
     "shell.execute_reply": "2025-01-29T16:40:04.460244Z",
     "shell.execute_reply.started": "2025-01-29T16:36:39.467681Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!python -m torch_ort.configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:40:09.713647Z",
     "iopub.status.busy": "2025-01-29T16:40:09.713327Z",
     "iopub.status.idle": "2025-01-29T16:40:11.901059Z",
     "shell.execute_reply": "2025-01-29T16:40:11.900343Z",
     "shell.execute_reply.started": "2025-01-29T16:40:09.713622Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GPU'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "from functools import partial\n",
    "from optimum.onnxruntime import ORTModelForSequenceClassification, ORTQuantizer, ORTTrainer, ORTTrainingArguments\n",
    "from optimum.onnxruntime.configuration import AutoQuantizationConfig, AutoCalibrationConfig\n",
    "\n",
    "ort.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:40:12.173598Z",
     "iopub.status.busy": "2025-01-29T16:40:12.173325Z",
     "iopub.status.idle": "2025-01-29T16:40:12.177283Z",
     "shell.execute_reply": "2025-01-29T16:40:12.176405Z",
     "shell.execute_reply.started": "2025-01-29T16:40:12.173576Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Defining trained BERT_base model as model_checkpoint because I compare base model result with the other versions\n",
    "\"\"\"\n",
    "model_checkpoint = './BERT_base-AG-NEWS'\n",
    "save_directory = 'tmp/onnx/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:40:14.649614Z",
     "iopub.status.busy": "2025-01-29T16:40:14.649312Z",
     "iopub.status.idle": "2025-01-29T16:40:16.047993Z",
     "shell.execute_reply": "2025-01-29T16:40:16.047146Z",
     "shell.execute_reply.started": "2025-01-29T16:40:14.649582Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d0877d785b94fc093765544029c3b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Tokenize test ds with text and labels columns for further testing\n",
    "\"\"\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "# tokenize and truncate dataset by batch, while removing unused column\n",
    "tokenized_test = datasets['test'].map(lambda x: tokenizer(x[\"text\"], truncation=True),\n",
    "                                 batched=True)\n",
    "\n",
    "# rename for multiclass fine-tuning\n",
    "tokenized_test_ds = tokenized_test.rename_column(\"label\", \"labels\")\n",
    "\n",
    "# set format to pytorch\n",
    "tokenized_test_ds.set_format(type=\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:40:20.206755Z",
     "iopub.status.busy": "2025-01-29T16:40:20.206432Z",
     "iopub.status.idle": "2025-01-29T16:40:35.217739Z",
     "shell.execute_reply": "2025-01-29T16:40:35.217050Z",
     "shell.execute_reply.started": "2025-01-29T16:40:20.206720Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Dynamic Quantization\n",
    "\"\"\"\n",
    "# Load a model from transformers and export it to ONNX\n",
    "ort_model = ORTModelForSequenceClassification.from_pretrained(model_checkpoint, export=True)\n",
    "\n",
    "# Save the ONNX model and tokenizer\n",
    "ort_model.save_pretrained(save_directory)\n",
    "\n",
    "# Define the quantization methodology\n",
    "qconfig = AutoQuantizationConfig.arm64(is_static=False, per_channel=False) # is_static is the param to choose dynamic/static quantization method\n",
    "quantizer = ORTQuantizer.from_pretrained(ort_model)\n",
    "\n",
    "# Apply dynamic quantization on the model\n",
    "quantizer.quantize(save_dir=save_directory, quantization_config=qconfig)\n",
    "\n",
    "# load quantized model\n",
    "quant_model = ORTModelForSequenceClassification.from_pretrained(save_directory, file_name=\"model_quantized.onnx\")\n",
    "# pass sentence through pipeline\n",
    "dynamic_pipe = pipeline(\"text-classification\", model=quant_model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some mismatching at the next steps of code snippet that's why I skipped 'device' argument (GPU/CPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:40:35.219363Z",
     "iopub.status.busy": "2025-01-29T16:40:35.219036Z",
     "iopub.status.idle": "2025-01-29T16:40:35.224164Z",
     "shell.execute_reply": "2025-01-29T16:40:35.223324Z",
     "shell.execute_reply.started": "2025-01-29T16:40:35.219327Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB):  110.0\n"
     ]
    }
   ],
   "source": [
    "print('Size (MB): ', np.round(os.path.getsize('tmp/onnx/model_quantized.onnx')/1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:42:31.636458Z",
     "iopub.status.busy": "2025-01-29T16:42:31.636122Z",
     "iopub.status.idle": "2025-01-29T16:47:49.624049Z",
     "shell.execute_reply": "2025-01-29T16:47:49.623175Z",
     "shell.execute_reply.started": "2025-01-29T16:42:31.636435Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80e08395984466e9591bc6af1f625be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.935921052631579, 'total_time_in_seconds': 317.098838808, 'samples_per_second': 23.967290541236324, 'latency_in_seconds': 0.04172353142210526}\n"
     ]
    }
   ],
   "source": [
    "task_evaluator = evaluator(\"text-classification\")\n",
    "\n",
    "eval_results_dynamic = task_evaluator.compute(\n",
    "    model_or_pipeline=dynamic_pipe,\n",
    "    tokenizer=tokenizer,\n",
    "    metric='accuracy',\n",
    "    input_column=\"text\",\n",
    "    label_column=\"labels\",\n",
    "    data=tokenized_test_ds,\n",
    "    label_mapping=quant_model.config.label2id,\n",
    ")\n",
    "\n",
    "print(eval_results_dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:47:58.965633Z",
     "iopub.status.busy": "2025-01-29T16:47:58.965328Z",
     "iopub.status.idle": "2025-01-29T16:48:26.584845Z",
     "shell.execute_reply": "2025-01-29T16:48:26.584000Z",
     "shell.execute_reply.started": "2025-01-29T16:47:58.965608Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06fee8283e204299a15a11cf23b0c2e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68fb2e8f9a5941afa231a97744b95d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/18.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f476a16811504fd1975a75efc56d0771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/1.23M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18eaa7c8fed43fdb1879399d7648e1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8b3c0df895347328f507237fe9436fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffdb072d3de14467a57926f89e029d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Static Quantization\n",
    "\"\"\"\n",
    "# set_static_qantization options\n",
    "onnx_model = ORTModelForSequenceClassification.from_pretrained(model_checkpoint, export=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "quantizer = ORTQuantizer.from_pretrained(onnx_model)\n",
    "qconfig = AutoQuantizationConfig.arm64(is_static=True, per_channel=False)\n",
    "\n",
    "# tokenizing cycle\n",
    "def preprocess_fn(ex, tokenizer):\n",
    "    return tokenizer(ex[\"text\"])\n",
    "    \n",
    "# load calibration dataset\n",
    "calibration_dataset = quantizer.get_calibration_dataset(\n",
    "    \"ag_news\",\n",
    "    # dataset_config_name=\"sst\",\n",
    "    preprocess_function=partial(preprocess_fn, tokenizer=tokenizer),\n",
    "    num_samples=50,\n",
    "    dataset_split=\"train\"\n",
    "    )\n",
    "\n",
    "# create calibration config(basic)\n",
    "calibration_config = AutoCalibrationConfig.minmax(calibration_dataset)\n",
    "\n",
    "# calibrating quantizer\n",
    "ranges = quantizer.fit(\n",
    "    dataset=calibration_dataset,\n",
    "    calibration_config=calibration_config,\n",
    "    operators_to_quantize=qconfig.operators_to_quantize\n",
    ")\n",
    "\n",
    "# quantizing\n",
    "model_quantized_path = quantizer.quantize(\n",
    "    save_dir=save_directory+'static_quantized.onnx',\n",
    "    calibration_tensors_range=ranges,\n",
    "    quantization_config=qconfig\n",
    "    )\n",
    "\n",
    "# pass sentence through pipeline\n",
    "static_quant_model = ORTModelForSequenceClassification.from_pretrained(model_quantized_path)\n",
    "static_pipe = pipeline(\"text-classification\", model=static_quant_model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:48:26.586384Z",
     "iopub.status.busy": "2025-01-29T16:48:26.586037Z",
     "iopub.status.idle": "2025-01-29T16:48:26.591432Z",
     "shell.execute_reply": "2025-01-29T16:48:26.590442Z",
     "shell.execute_reply.started": "2025-01-29T16:48:26.586349Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB):  0.004\n"
     ]
    }
   ],
   "source": [
    "print('Size (MB): ', np.round(os.path.getsize('tmp/onnx/static_quantized.onnx')/1e6, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:48:49.573267Z",
     "iopub.status.busy": "2025-01-29T16:48:49.572974Z",
     "iopub.status.idle": "2025-01-29T16:55:47.555584Z",
     "shell.execute_reply": "2025-01-29T16:55:47.554721Z",
     "shell.execute_reply.started": "2025-01-29T16:48:49.573246Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9303947368421053, 'total_time_in_seconds': 417.4914435290002, 'samples_per_second': 18.20396589630245, 'latency_in_seconds': 0.05493308467486845}\n"
     ]
    }
   ],
   "source": [
    "eval_results_static = task_evaluator.compute(\n",
    "    model_or_pipeline=static_pipe,\n",
    "    tokenizer=tokenizer,\n",
    "    metric='accuracy',\n",
    "    input_column=\"text\",\n",
    "    label_column=\"labels\",\n",
    "    data=tokenized_test_ds,\n",
    "    label_mapping=static_quant_model.config.label2id,\n",
    ")\n",
    "\n",
    "print(eval_results_static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:57:10.040349Z",
     "iopub.status.busy": "2025-01-29T16:57:10.040053Z",
     "iopub.status.idle": "2025-01-29T16:57:13.456549Z",
     "shell.execute_reply": "2025-01-29T16:57:13.455893Z",
     "shell.execute_reply.started": "2025-01-29T16:57:10.040328Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "404d74cb6b3548b0b8dd5a5f79eac941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Quantization aware training\n",
    "\"\"\"\n",
    "# Load unpretrained model and quantize while training is going.\n",
    "# I will take dataset which I already used with distiled models, and the same model params\n",
    "model_qat = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=4).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Dataset preprocessing\n",
    "tokenized_ds = tokenize(datasets, tokenizer=tokenizer)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = ORTTrainingArguments(\n",
    "    output_dir=\"./results_quantized\",\n",
    "    save_strategy = 'epoch',\n",
    "    optim=\"adamw_ort_fused\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    fp16=True,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    group_by_length=True\n",
    ")\n",
    "\n",
    "# Create ONNX Runtime Trainer\n",
    "trainer_quantized_model = ORTTrainer(\n",
    "    model=model_qat,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds['train'],\n",
    "    eval_dataset=tokenized_ds['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T16:57:26.507793Z",
     "iopub.status.busy": "2025-01-29T16:57:26.507493Z",
     "iopub.status.idle": "2025-01-29T17:13:15.406913Z",
     "shell.execute_reply": "2025-01-29T17:13:15.405995Z",
     "shell.execute_reply.started": "2025-01-29T16:57:26.507770Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3375' max='3375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3375/3375 15:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.357700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.232600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.206800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.196200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.187600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.178700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 38s, sys: 16.5 s, total: 18min 54s\n",
      "Wall time: 15min 48s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3375, training_loss=0.22043081552010996, metrics={'train_runtime': 907.712, 'train_samples_per_second': 118.98, 'train_steps_per_second': 3.718, 'total_flos': 3146733172058112.0, 'train_loss': 0.22043081552010996, 'epoch': 1.0})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model while applying quantization\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#29/01/25\n",
    "%time trainer_quantized_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T17:13:24.977672Z",
     "iopub.status.busy": "2025-01-29T17:13:24.977380Z",
     "iopub.status.idle": "2025-01-29T17:13:26.012187Z",
     "shell.execute_reply": "2025-01-29T17:13:26.011482Z",
     "shell.execute_reply.started": "2025-01-29T17:13:24.977652Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Export the quantized model and save it\n",
    "trainer_quantized_model.save_model(\"./model_qat_aware_training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T17:13:42.711730Z",
     "iopub.status.busy": "2025-01-29T17:13:42.711449Z",
     "iopub.status.idle": "2025-01-29T17:13:42.716554Z",
     "shell.execute_reply": "2025-01-29T17:13:42.715683Z",
     "shell.execute_reply.started": "2025-01-29T17:13:42.711709Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB):  0.004096\n"
     ]
    }
   ],
   "source": [
    "print('Size (MB): ', os.path.getsize('model_qat_aware_training')/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T17:13:52.564006Z",
     "iopub.status.busy": "2025-01-29T17:13:52.563700Z",
     "iopub.status.idle": "2025-01-29T17:14:27.381520Z",
     "shell.execute_reply": "2025-01-29T17:14:27.380773Z",
     "shell.execute_reply.started": "2025-01-29T17:13:52.563983Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7600"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Evaluation\n",
    "\"\"\"\n",
    "preds = trainer_quantized_model.predict(tokenized_ds['test'])\n",
    "\n",
    "preds_flat = [np.argmax(x) for x in preds[0]]\n",
    "len(preds_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T17:14:29.692835Z",
     "iopub.status.busy": "2025-01-29T17:14:29.692508Z",
     "iopub.status.idle": "2025-01-29T17:14:29.703279Z",
     "shell.execute_reply": "2025-01-29T17:14:29.702455Z",
     "shell.execute_reply.started": "2025-01-29T17:14:29.692785Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Quantization aware training: 0.941\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(tokenized_datasets['test']['labels'], preds_flat)\n",
    "print(f'Accuracy Quantization aware training: {np.round(acc, 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T17:14:42.737601Z",
     "iopub.status.busy": "2025-01-29T17:14:42.737294Z",
     "iopub.status.idle": "2025-01-29T17:14:42.769525Z",
     "shell.execute_reply": "2025-01-29T17:14:42.768808Z",
     "shell.execute_reply.started": "2025-01-29T17:14:42.737578Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model name</th>\n",
       "      <th>Accuracy score on test data</th>\n",
       "      <th>Model size (MiB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bert</td>\n",
       "      <td>0.94</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Distil_Bert</td>\n",
       "      <td>0.938</td>\n",
       "      <td>267.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tiny_Bert</td>\n",
       "      <td>0.91</td>\n",
       "      <td>57.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MiniLM</td>\n",
       "      <td>0.93</td>\n",
       "      <td>133.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dynamic_Quantization</td>\n",
       "      <td>0.935</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Static_Quantization</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Quantization_aware_training</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model name Accuracy score on test data Model size (MiB)\n",
       "0                         Bert                        0.94              438\n",
       "1                  Distil_Bert                       0.938           267.86\n",
       "2                    Tiny_Bert                        0.91            57.43\n",
       "3                       MiniLM                        0.93           133.51\n",
       "4         Dynamic_Quantization                       0.935              110\n",
       "5          Static_Quantization                        0.93            0.004\n",
       "6  Quantization_aware_training                        0.94            0.004"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_df = pd.DataFrame(\n",
    "    {'Model name': ['Bert', 'Distil_Bert', 'Tiny_Bert', 'MiniLM', 'Dynamic_Quantization', 'Static_Quantization', 'Quantization_aware_training'],\n",
    "     'Accuracy score on test data': ['0.94', '0.938', '0.91', '0.93', '0.935', '0.93', '0.94'],\n",
    "     'Model size (MiB)': ['438', '267.86', '57.43', '133.51', '110', '0.004', '0.004']\n",
    "    }\n",
    ")\n",
    "\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "As can be seen from the results tables, the success of the models does not vary by a great margin.\n",
    "But distilled and quantized models' size is much smaller than bert_base model. It's great!"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
